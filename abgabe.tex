\documentclass[notitlepage, hidelinks]{article}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{float}
\usepackage{tabularx}
\usepackage[font=footnotesize,labelfont=bf]{caption}
\usepackage{fancyvrb}
\usepackage[ngerman]{babel}
\usepackage{ifxetex,ifluatex}
\usepackage{etoolbox}
\usepackage[svgnames]{xcolor}
\usepackage{tikz}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{color, colortbl}
\usepackage{wrapfig}
\usepackage{changepage}
\usepackage{listings}
\usepackage[hyphens]{url}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{caption}
\usepackage{framed}

\newcommand\ytl[2]{
\parbox[b]{16em}{\hfill{\color{black}\bfseries #1}~$\cdots\cdots$~}\makebox[0pt][c]{$\bullet$}\vrule\quad \parbox[c]{14.5cm}{\vspace{10pt}\color{black}\raggedright #2.\\[10pt]}\\[-3pt]
}

\definecolor{Gray}{gray}{0.75}
\definecolor{LightGray}{gray}{0.9}

\definecolor{red}{rgb}{0.3,0.3,0.3} 
\definecolor{blue}{rgb}{0.023,0.49,0.0117}
\definecolor{green}{rgb}{0,0.8,0}
\definecolor{cyan}{rgb}{0.0,0.38,0.51}
\definecolor{cloudwhite}{rgb}{1, 1, 1}
\definecolor{black}{rgb}{0,0,0}
\definecolor{bluebg}{rgb}{0.3,0.3,0.3}

\lstset{
language=csh,
basicstyle=\footnotesize\ttfamily,
numbers=left,
numberstyle=\tiny,
numbersep=5pt,
tabsize=1,
extendedchars=true,
breaklines=true,
frame=b,
stringstyle=\color{blue}\ttfamily,
showspaces=false,
showtabs=false,
xleftmargin=20pt,
xrightmargin=3pt,
framexleftmargin=17pt,
framexrightmargin=5pt,
framexbottommargin=4pt,
commentstyle=\color{green},
morecomment=[l]{//}, %use comment-line-style!
morecomment=[s]{/*}{*/}, %for multiline comments
showstringspaces=false,
morekeywords={ abstract, event, new, struct,
as, explicit, null, switch,
base, extern, object, this,
bool, false, operator, throw,
break, finally, out, true,
byte, fixed, override, try,
case, float, params, typeof,
catch, for, private, uint,
char, foreach, protected, ulong,
checked, goto, public, unchecked,
class, if, readonly, unsafe,
const, implicit, ref, ushort,
continue, in, return, using,
decimal, int, sbyte, virtual,
default, interface, sealed, volatile,
delegate, internal, short, void,
do, is, sizeof, while,
double, lock, stackalloc,
else, long, static,
enum, namespace, string},
keywordstyle=\color{cyan},
identifierstyle=\color{black},
backgroundcolor=\color{cloudwhite},
}



\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox{bluebg}{\parbox{\textwidth}{\hspace{15pt}#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white, singlelinecheck=false, margin=0pt, font={bf,footnotesize}}
\lstset{defaultdialect=[Sharp]C}


\setcounter{tocdepth}{5}
\setcounter{secnumdepth}{5}


\usetikzlibrary{backgrounds}
\makeatletter


% environment derived from framed.sty: see leftbar environment definition
\definecolor{formalshade}{rgb}{0.95,0.95,1}

\newenvironment{formal}{%
  \def\FrameCommand{%
    \hspace{1pt}%
    {\color{black}\vrule width 2pt}%
    {\color{formalshade}\vrule width 4pt}%
    \colorbox{formalshade}%
  }%
  \MakeFramed{\advance\hsize-\width\FrameRestore}%
  \noindent\hspace{-4.55pt}% disable indenting first paragraph
  \begin{adjustwidth}{}{7pt}%
  \vspace{2pt}\vspace{2pt}%
}
{%
  \vspace{2pt}\end{adjustwidth}\endMakeFramed%
}


\pgfmathsetmacro{\fq@width}{\linewidth - 2*\pgf@x}


\renewcommand{\figurename}{Abb.}
\geometry{left=3cm, right=3cm, bottom=2cm, top=2.5cm}
\titlespacing*{\section}{0pt}{7ex plus 1ex minus .2ex}{4.3ex plus .2ex}
\titlespacing*{\subsection}{0pt}{7ex plus 1ex minus .2ex}{4.3ex plus .2ex}
\setlength\parindent{0pt}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\def\changemargin#1#2{\list{}{\rightmargin#2\leftmargin#1}\item[]}
\let\endchangemargin=\endlist 


\begin{document}

\mbox{}\\ \mbox{}\\\mbox{}\\ \mbox{}\\\mbox{}\\ \mbox{}\\\mbox{}\\\mbox{}\\
\mbox{}\\\mbox{}\\\mbox{}\\\mbox{}\\\mbox{}\\\mbox{}\\\mbox{}\\\mbox{}\\
\begin{center}
\huge
\textbf{E-Business Architekturen} \\ 
\LARGE
Prüfungsleistung (Gruppenaufgabe) \\
\mbox{}\\
\large
Ergebnisprotokolle der Komplexübungen 1, 2, 3b und 4d im Rahmen der Veranstaltung E-Business Architekturen  \\

\mbox{}\\ \mbox{}\\
\large
vorgelegt am \\
07.05.2023 \\
\mbox{}\\
an der \\
Hochschule für Wirtschaft und Recht Berlin \\
Fachbereich Duales Studium \\
\end{center}

\mbox{}\\ \mbox{}\\\mbox{}\\ \mbox{}\\\mbox{}\\ \mbox{}\\\mbox{}\\ \mbox{}\\\mbox{}\\ \mbox{}\\
\begin{table}[H]
\begin{tabular}{ l l }
von: 
& Robert Neubert \\
& Danny Neupauer \\
& Hannes Roever \\
Fachrichtung: & Wirtschaftsinformatik \\
Studienjahrgang: & WI20C \\
Studienhalbjahr:& Wintersemester 2022/23 \\
Dozent: & Prof. Dr. Andreas Schmietendorf \\
\end{tabular}
\end{table}

\thispagestyle{empty}
\clearpage
\newpage
\tableofcontents
\thispagestyle{empty}
\clearpage

\normalsize
\pagenumbering{arabic}


\section{Einleitung}

\section{Aufgabe 1: E-Business Grundlagen}

\subsection{Anwendung des Begriffs E-Business}
Was verbinden Sie mit dem Begriff des E-Business? Versuchen Sie die folgenden Aspekte zu berücksichtigen, nennen Sie ggf. weitere.
\begin{itemize}
\item Organisatorische Aspekte
\item Prozessbezogene Aspekte (z.B. Geschäftsprozess)
\item Technologische Aspekte (z.B. Entwicklung \& Betrieb)
\item Gesellschaftliche Implikationen (z.B. Soziologische Aspekte)
\end{itemize}

\subsection{Beziehung zu domänenspezifischen Lösungen}
Welche Beziehungen sehen Sie zu den folgenden Lösungen?
\begin{itemize}
\item Systeme für das e-Learning (z.B. Moodle oder Open HPI)
\item Systeme für das e-Government (z.B. ELSTER oder Fahrzeugzulassung)
\item Systeme für das e–Banking (z.B. Instant Payment)
\item Systeme für das e-Commerce (z.B. Web Shops)
\end{itemize}

\subsection{Ziele und Erwartungen an E-Business Lösungen}
Welche Ziele und Erwartungen verknüpfen Unternehmen und ihre Kunden mit e-Business-Lösungen?
\begin{itemize}
\item Berücksichtigen sie ggf. unterschiedliche Sichten
\item Nennen Sie ihnen bekannte Lösungen (z.B. aus den Praktika)
\item Identifizieren Sie mögliche Vor- und Nachteile
\end{itemize}

\begin{table}[ht]
\centering
\caption{Vor- und Nachteile von E-Commerce aus verschiedenen Perspektiven}
\label{table:e-commerce}
\begin{tabular}{|l|p{6cm}|p{6cm}|}
\hline
\textbf{Sichtweise} & \textbf{Vorteile} & \textbf{Nachteile} \\
\hline
Unternehmen & \begin{itemize}\item Erhöhte Reichweite und Kundenzugang\item Kosteneinsparungen durch Automatisierung und Effizienzsteigerung\item Erhöhte Flexibilität und Anpassungsfähigkeit\end{itemize} & \begin{itemize}\item Höhere Investitionskosten\item Datenschutz- und Sicherheitsrisiken\item Abhängigkeit von Technologie und Infrastruktur\end{itemize} \\
\hline
Kunden & \begin{itemize}\item Bequemlichkeit und Flexibilität\item Personalisierte Erfahrungen\item Bessere Transparenz und Vergleichbarkeit von Angeboten\end{itemize} & \begin{itemize}\item Datenschutz- und Sicherheitsrisiken\item Mangelnde persönliche Beratung und menschlicher Kontakt\end{itemize} \\
\hline
Lieferanten & \begin{itemize}\item Effizientere Transaktionsabwicklung und bessere Sichtbarkeit von Kundenbedarf\item Stärkere Kundenbindung und Zusammenarbeit\item Potenziell höhere Margen\end{itemize} & \begin{itemize}\item Investitions- und Implementierungskosten\item Abhängigkeit von Technologie und Infrastruktur\item Potenziell höheres Risiko im Hinblick auf Zahlungsverzögerungen und Ausfallrisiken\end{itemize} \\
\hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{|L{2cm}|L{2.8cm}|L{2.8cm}|L{2.8cm}|L{2.8cm}|}
\hline
Schritt & Endkunde & Shopbetreiber & Schnittstellen & physisch \\ \hline
Produkt suchen & Browser & Produktverwaltung Plugin & Google (Analytics, Adwords) & \\ \hline
Bestellung aufgeben & Browser & Shopify/ Woocommerce & Zahlungsanbieter, Logistikservice (DHL) & \\ \hline
Bestellung verschicken & Browser/OS (Mail) & Paketschein drucken / Onlinefrankierung & API DHL, API Mailing (Plugin Shopsystem) & Paket abgeben \\ \hline
Bestellung unterwegs & Browser/OS (Mail/App) & Bestellungsübersicht/ Tracking & DHL (Shopsystem-Zentrale, Fahrzeug-Zentrale) & Paket scannen \\ \hline
Bestellung annehmen & & Update Bestellstatus & DHL (Shopsystem-Zentrale, Fahrzeug-Zentrale) & Paket abgeben, Statusupdate \\ \hline
\end{tabular}
\caption{Prozessschritte im Online-Shop aus Endkunden- und Shopbetreibersicht am Beispiel einer Paketzustellung von DHL (Praxisstelle Robert Neubert}
\end{table}

\subsection{Eigenschaften von E-Business Softwarearchitekturen}
Über welche Eigenschaften sollten Softwarearchitekturen für e-Business-Lösungen verfügen?
\begin{itemize}
\item Fragen des Kommunikationssystems
\item Verwendete Rechnerinfrastruktur
\item Eigenschaften entwickelter Softwaresysteme
\end{itemize}

\begin{table}[ht]
\centering
\caption{Eigenschaften von hochwertiger Software}
\label{table:software-qualities}
\begin{tabular}{|l|p{6cm}|p{6cm}|}
\hline
\textbf{Eigenschaft} & \textbf{Beschreibung} & \textbf{Merkmale/Beispiele} \\
\hline
Skalierbarkeit & Steigende Datenmengen und Anfragen bewältigen & Scale up und Scale out, Load Balancing, Virtualisierung \\ \hline
Flexibilität & Anpassungsfähigkeit an sich ändernde Anforderungen und Geschäftsprozesse & API-First-Ansatz, Microservices, modulare Codebasis \\ \hline
Sicherheit & Maßnahmen zur Absicherung der Daten, Transaktionen und Systeme & Zertifikate, Verschlüsselung, Zugriffs- und Berechtigungskontrollen, Penetrationstests \\ \hline
Integration & Fähigkeit zur nahtlosen Integration mit anderen Systemen und Plattformen & APIs, Interoperabilität, standardisierte Formate \\ \hline
Wartbarkeit & Leichte Wartbarkeit und Aktualisierbarkeit der Software, schnelle Fehlerbehebung & Modularer Aufbau, klare Schnittstellen, automatisierte Tests, Dokumentation \\ \hline
Leistung & Schnelligkeit und Zuverlässigkeit der Systeme und Transaktionen & Caching, Zugriffsptimierung von Datenbankzugriffen, Monitoring, Fallbacks \\ \hline
Testbarkeit & Möglichkeit zur einfachen und effektiven Durchführung von Tests & Test-Driven-Development (TDD), Integration von Test-Tools, hohe Code-Qualität, Dependency Inversion Principle \\ \hline
Unabhängigkeit & Vermeidung von zu vielen Abhängigkeiten von externen Bibliotheken oder Frameworks & Verwendung von Standard-Protokollen, Implementierung eigener Komponenten, geringe Kopplung \\ \hline
Deployment & Leichtes und automatisiertes Deployment von Softwarekomponenten & Continuous Integration/Deployment (CI/CD), Container-Technologien, automatisierte Deployment-Pipelines \\ \hline
\end{tabular}
\end{table}

\subsection{E-Business im konkreten Unternehmenskontext}
Wie könnte eine Strategie zur Einführung einer e-Business-Architektur in einem Unternehmen ihrer Wahl aussehen?
\begin{itemize}
\item Notwendige Voraussetzungen \& Rahmenbedingungen
\item Auswirkungen auf das Informationsmanagement (CIO)
\item Auswirkungen auf die Entwicklung von Software (Lösungsanbieter)
\item Auswirkungen auf den Betrieb von Software (Rechenzentren)
\item Mehrwertpotentiale für die Kunden und Lieferanten
\end{itemize}

Worin sehen Sie weitere Aspekte eines digitalen Unternehmens, die mit dem Begriff des e-Business nicht erfasst werden?

\newpage

\section{Aufgabe 2: Serviceverzeichnisse}
\subsection{Analyse eines Verzeichnisdienstes}

In dieser Unteraufgabe wird sich mit der Nutzung und Analyse von Service-Verzeichnissen beschäftigt. Dazu wird sich zunächst für einen zu betrachtenden Verzeichnisdienst entschieden, welcher im weiteren Verlauf der Aufgabe auf seine Eigenschaften überprüft wird.

\subsubsection{Vorgehensweise bei der Auswahl eines Verzeichnisdienstes}
Um einen vollumfänglichen Überblick über den Verzeichnisdienst bieten zu können, wurde bei der Auswahl des Verzeichnisdienstes darauf geachtet, einen Verzeichnisdienst ohne Zugangsbeschränkungen mit öffentlich zugänglichen APIs zu wählen. Aufgrund dieser Vorgaben wir uns für das API-Verzeichnis des Bundes entschieden. \\
Die APIs, die unter der Webadresse https://bund.dev/apis (Abb.\ref{bundwebsite}) zusammengefasst sind, dienen dem Zweck, den Zugang zu verschiedenen Datensätzen und Verwaltungsverfahren der Bundesverwaltung zu erleichtern. Sie ermöglichen es Entwicklern und anderen interessierten Nutzern, auf eine standardisierte und dokumentierte Art und Weise auf diese Informationen zuzugreifen und sie in eigenen Anwendungen zu nutzen. Dabei können die APIs verschiedene Funktionalitäten bereitstellen, wie beispielsweise die Abfrage von Daten, die Bearbeitung von Anträgen oder die Einreichung von Dokumenten. Durch die Bereitstellung dieser APIs im Rahmen der Open Government Umsetzungsstrategie des Bundes wird eine transparentere und effizientere Zusammenarbeit zwischen Verwaltung und Bürgern angestrebt. 

\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/bundwebsite.png}
  \caption{Ansicht der Startseite des Verzeichnisdienstes}
  \label{bundwebsite}
\end{figure}


\subsubsection{Allgemeines über den Verzeichnisdienst}
In ihrer Gesamtheit sind auf der Website insgesamt 47 diverse Web-APIs identifizierbar. Das Verzeichnis bietet keine Filter-, Sortier- oder Suchfunktionen und ist als einfache Liste dargestellt (Abb.\ref{bundwebsite2}). 

\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/bundwebsite2.png}
  \caption{Ansicht der Startseite des Verzeichnisdienstes (runtergescrollt)}
  \label{bundwebsite2}
\end{figure}

Alle APIs sind im REST Architekturstil umgesetzt, was quantitativ die Ergebnisse von Umfragen in der Industrie und  unter Entwicklern abbildet (s. Abb.\ref{stateofapitechs}). Die APIs können hauptsächlich verschiedenen Bundes- und nachgeordneten Behörden zugeordnet werden. Jedoch lassen sich vereinzelt auch APIs von Landesbehörden sowie von Anstalten des öffentlichen Rechts ausmachen.


\begin{figure}[H]
\centering
  \includegraphics[width=350px]{images/stateofapitechs.png}
\caption{Architekturstil eingesetzter APIs\protect\footnote{\cite{api-postman}}}
  \label{stateofapitechs}
\end{figure}


Die Qualität der bereitgestellten Dokumentationen variiert und erstreckt sich von minimalen Informationen auf Github (Abb.\ref{bundwebsite3}) mit einem einzigen Beispiel (oder der Information, die API sei deaktiviert), über mal schlechter, mal besser Nutzung von Open API (mit Swagger UI, Abb.\ref{bundwebsite4}) bis hin zu umfangreichen und gut strukturierten Dokumentationen, teilweise mit eigener Webpräsenz (FIT-Connect, Abb.\ref{bundwebsite5}).

\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/bundwebsite4.png}
  \caption{rudimentäre Dokumentation auf Github (Bundeshaushalt API)}
  \label{bundwebsite4}
\end{figure}

\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/bundwebsite3.png}
  \caption{gute, standardisierte Dokumentation mit Swagger UI (Arbeitsagentur API)}
  \label{bundwebsite3}
\end{figure}

\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/bundwebsite5.png}
  \caption{nicht standardisierte, sehr umfangreiche Dokumentation in eigenen Format (FIT CONNECT, mehrere APIs)}
  \label{bundwebsite5}
\end{figure}


Das Hochladen selbst entwickelter API´s ist auf der BundDev Platform nicht vorgesehen. Es besteht aber die Möglichkeit über die GitHub Verbindung eigene Forks zu kreieren und diese zu verändern und anzupassen. Die Aktualität variiert, die letzten Aktualisierungen in den Repositories (oft 2 Jahre her) deuten jedoch auf eine im Vergleich zum Industriedurchschnitt deutlich geringere Deploymentfrequenz hin (s. auch Abb.\ref{stateofapideploymentfreq}.

\begin{figure}[H]
\centering
  \includegraphics[width=350px]{images/stateofapideploymentfreq.png}
  \caption{Deploymentfrequenz von APIs\protect\footnote{\cite{api-postman}}}
  \label{stateofapideploymentfreq}
\end{figure}

 Da viele Datengrundlagen die von den API´s genutzt werden öffentlich zugänglich sind besteht auch die Möglichkeit mit Origninaldaten zu arbeiten. Nachdem der Code angepasst oder verbessert wurde lässt sich dieser über einen Pull Request in den ursprünglichen Code integrieren. 
Das Melden von Problemen und Bugs ist in einigen Fällen nur über GitHub möglich (Abb.\ref{gitissues}). In wenigen Dokumentationen ist eine Kontaktemail hinterlegt. Eine standardisierte Vorlage für das Reporting von Schwierigkeiten besteht nicht.

\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/gitissues.png}
  \caption{Gitrepo der ``populärsten'' API (Autobahn API), Ansicht offener Issues. Oben sind auch die 4 offenen PRs, 10 Forks und 111 Sterne zu sehen (Stand: 7.5.2023)}
  \label{gitissues}
\end{figure}

Wie in (Abb.\ref{gitissues}) ersichtlich ist, können bei der Erstellung von Problemen verschiedene Tags zugeordnet werden, um eine Klassifizierung für den Entwickler zu erleichtern.
Der Verzeichnisdienst ist ohne vorherige Anmeldung oder Registrierung zugänglich. Ebenso kann der API-Code ohne GIT-Registrierung oder Anmeldung heruntergeladen werden. Das Melden von Problemen über die GIT-Funktion erfordert jedoch eine vorherige Anmeldung und Registrierung. Analog dazu verhält es sich bei verfügbaren Pull Requests und ähnlichen Funktionalitäten.

\subsubsection{Vergleich von API- und datenorientierten Schnittstellen}
Die in der Aufgabe genannte Differenzierung in API und datenorientierten Schnittstelle ist aus unserer Sicht nicht sinnvoll. API steht für Application Programming Interface, zu deutsch laut Wikipedia Programmierschnittstelle oder Anwendungsschnittstelle. Diese sind wiederum in die in Tabelle \ref{apiscategories} dargestellten Kategorien unterteilt.\footnote{Vgl. \cite{api-wiki}} Datei- oder datenorientierte Schnittstellen sind dabei eine der Kategorien. REST APIs sind hingegen am ehesten den protokollorientierten Schnittstellen zuzuordnen, da sie architektonisch bedingt vom HTTP(S) Protokoll abhängen.\footnote{Vgl. \cite{api-systempilot}}

\begin{table}[H]
\begin{center}
\begin{tabular}{|L{2cm}|L{2.8cm}|L{2.8cm}|L{2.8cm}|L{2.8cm}|}
\hline
Schnittstellen-Typ & Funktionsorientierte PS & Dateiorientierte PS & Objektorientierte PS & Protokollorientierte PS \\
\hline
Beschreibung & Stellt Funktionen zur Verfügung, die von anderen Anwendungen aufgerufen werden können. & Bietet die Möglichkeit, auf Daten in Dateien zuzugreifen und diese zu verarbeiten. & Basiert auf Objekten, die Funktionen und Eigenschaften enthalten und von anderen Anwendungen verwendet werden können. & Bietet eine strukturierte Art und Weise, um Daten zwischen Systemen auszutauschen. \\
\hline
Beispiele & DLL, Programm-APIs, Bibliotheken & CSV, XML, JSON & COM, CORBA, SOAP & HTTP, TCP/IP, FTP \\
\hline
Verwendung & Häufig in einfachen Anwendungen verwendet. & Nützlich für Anwendungen, die mit großen Datenmengen arbeiten. & Komplexere Anwendungen, die eine umfangreichere Struktur benötigen. & Weit verbreitet in verteilten Systemen und bei der Kommunikation zwischen verschiedenen Anwendungen. \\
\hline
Vorteile & Schnell und einfach zu implementieren. & Gut geeignet für die Arbeit mit großen Datenmengen. & Bietet eine flexible Art der Datenverarbeitung und -speicherung. & Bietet eine standardisierte Art der Kommunikation zwischen Systemen. \\
\hline
Nachteile & Kann bei komplexen Anwendungen unübersichtlich werden. & Begrenzte Funktionalität im Vergleich zu anderen Schnittstellentypen. & Komplex in der Implementierung und erfordert mehr Aufwand. & Kann weniger effizient als andere Schnittstellentypen sein. \\
\hline
\end{tabular}
\caption{Kategorisierung APIs}
\label{apiscategories}
\end{center}
\end{table}


\subsection{Analyse von Web-APIs}

\subsubsection{Erstellung des Bewertungsmodells}

Wir haben uns dazu entschieden alle APIs aus dem BundDev Verzeichnis zu bewerten. So ist es möglich eine Übersicht der vom Bund bereitgestellten Schnittstellen zu gewinnen. Zu Beginn wurde das Bewertungsmodell in fünf Kategorien aufgeteilt. Diese lauten: Übersicht, Offenheit, Qualität, Dokumentation und Verfügbarkeit.

\begin{enumerate}
\item In diesem Teil wird nur eine Übersicht über die einzelnen API´s dargestellt. Unter welchen URL lässt sich die Dokumentation finden? Wie viele get, post, put, delete und andere werden werden in der API verwendet? Hierbei wird keine Bewertung vorgenommen, sondern es wird nur aufgezählt.
\item Offenheit: 
\begin{itemize}
\item Quellcode: Die Offenlegung des Quellcodes einer API fördert Transparenz und Anpassungsfähigkeit, indem sie Entwicklern Einblicke in die Funktionsweise der API gewährt und die Möglichkeit bietet, die API an individuelle Bedürfnisse anzupassen sowie Fehler zu beheben.
\item Insofern ein Token zur Nutzung notwendig ist, sollte dies einfach, kostenlos und umgehend zur Verfügung gestellt werden (nach Registrierung)
\item Zugänglichkeit: Dokumentation, Beispiele, Kontakt, verwendete Sprache (englisch, keine Fachbegriffe und Abkürzungen) sind nachvollziehbar und gut auffindbar
\item Kontakt: Verantwortlicher und ggfs. Entwickler können direkt erreicht werden
\end{itemize}
\item Qualität: 
\begin{itemize}
\item Granularität: zu gering (wenige Ressourcen mit wenigen Routen geben sehr große Objekte zurück) bis zu hoch (für ``normale'' Usecases müssen für ein clientrelevantes Objekt mehrere Abfragen gestellt werden)
\item TLS: ausschließlich oder Weiterleitung bei HTTP Aufruf (gut) über HTTP möglich (mittel) bis nur unter HTTP erreichbar (schlecht)
\item Statuscode: Werden alle relevanten Statuscodes in den Dokumentationen genannt und ausreichen beschrieben?
\item Ressourcen fachlich korrekt ausgewählt?
\item Routen in angemessener Tiefe?
\end{itemize}
\item Dokumentation:
\begin{itemize}
\item Routen: beschrieben, Datentypen, Beispiele
\item Ressourcen: benannt, Request und Response Modelle verfügbar (required? usw.)
\item Parameter: benannt, Datentypen, Beispiele
\end{itemize}
\item Verfügbarkeit und Performance
\end{enumerate}


\subsubsection{Einsatz des Bewertungsmodells}

\begin{table}[H]
\begin{center}
\begin{tabular}{|p{3.6cm}|p{8.5cm}|p{2.5cm}|}
\hline
\textbf{Bewertungsteil} & \textbf{Beschreibung} & \textbf{Punkte}\\ \hline
Token/Registrierung & Nicht notwendig ODER notwendig, aber leicht einzurichten. Wenn ja, mit Token sind alle Endpunkte verfügbar & 2\\ \hline
& Notwendig, aber auch dann nicht alle Endpunkte verfügbar ODER notwendig, aber mit Hürden einzurichten & 1\\ \hline
& Für alle Endpunkte nötig UND mit Hürden einzurichten ODER Token ungültig & 0\\ \hline
Quellcode & Liegt vor und ist verlinkt & 1\\ \hline
& Liegt nicht vor oder muss erst gesucht werden & 0\\ \hline
Request Limit & Wenn nicht angegeben, stellen wir verteilt über 30 Minuten 1000 Anfragen. Wenn das klappt, gibt es zwei Punkte. & \\ \hline
& $<$ 100 & 0 \\ \hline
& $<$ 1000 & 1 \\ \hline
& $<$ 10k & 2 \\ \hline
& $>$ 10k & 3 \\ \hline
Kontakt & Ja (Link/E-Mail) & 1 \\ \hline
& nein & 0 \\ \hline
\end{tabular}
\caption{Bewertungsschema Offenheit}
\label{Offenheit}
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{|p{3.6cm}|p{8.5cm}|p{2.5cm}|}
\hline
\textbf{Bewertungsteil} & \textbf{Beschreibung} & \textbf{Punkte}\\ \hline
Granularität & Ausgeglichen, sowohl Listen als auch Einschränkungen auf einzelne Objekte & 1 \\ \hline
& Sehr viele Use Cases mit einzelnen Endpunkten oder eine Anfrage erfordert verschiedene Ressourcen & 0 \\ \hline
& Zu geringe Granularität, sehr wenige Endpunkte mit zu umfangreichen Datenmodellen & 0 \\ \hline
Transportverschlüsselung & HTTPS und gegebenenfalls Weiterleitung von HTTP auf HTTPS & 2 \\ \hline
& HTTP und HTTPS, aber keine Weiterleitung von HTTP & 1 \\ \hline
& Nur HTTP & 0 \\ \hline
Routen & Jede Ressource hat einen Identifier und ist mit Nomen benannt. HTTP-Methoden sind korrekt eingesetzt. Maximale Tiefe beträgt 3. & 2 \\ \hline
& Mindestens 2 Bedingungen aus 2 sind erfüllt & 1 \\ \hline
& Eine oder keine Bedingung aus 2 erfüllt & 0 \\ \hline
Statuscodes & 200, 201, 204, 400, 401, 403, 404, 409, 500, 503 & 2\\ \hline
& Mind. 200, 201, 400, 404, 500 & 1\\ \hline
& Keine & 0\\ \hline
MIME Types & JSON und/ oder XML/ plain text & 2\\ \hline
& Nur XML und/ oder plain text & 1\\ \hline
& Keine/ plain & 0\\ \hline
Versionierung & Verschiedene Majorversionen = 2 & \\ \hline
& Nur latest = 1 & \\ \hline
& Nicht angegeben = 0 & \\ \hline
\end{tabular}
\caption{Bewertungsschema Qualität}
\label{quality}
\end{center}
\end{table}


\begin{table}[H]
\begin{center}
\begin{tabular}{|p{3.6cm}|p{8.5cm}|p{2.5cm}|}
\hline
\textbf{Bewertungsteil} & \textbf{Beschreibung} & \textbf{Punkte}\\ \hline
Routen & alle Routen mit Beispielen (Request/Response), wenn nicht sprechend mit Erläuterung, alle notwendigen und optionalen Parameter sind angegeben & 2 \\ \hline
& wie zwei, aber nur teilweise erfüllt & 1 \\ \hline
& Keine Doku & 0 \\ \hline
Ressourcen & alle Resourcen dokumentiert mit Beispielen, Datentyp und ggfs. default Wert & 2 \\ \hline
& wie zwei, aber nur teilweise erfüllt & 1 \\ \hline
& Keine Doku & 0 \\ \hline
Parameter & alle Parameter mit Datentyp, erlaubtem Werteraum, required und - wenn nicht sprechend - mit Beispiel, ggfs Differenzierung der Rückgabeobjekte ist dokumentiert & 2 \\ \hline
& wie zwei, aber nur teilweise erfüllt & 1 \\ \hline
& Keine Doku & 0 \\ \hline
Statuscodes & Responsecodes mit Zahl, Rückgabestring und Datentyp, Mimetype oder Datenmodell dokumentiert & 2 \\ \hline
& wie zwei, aber nur teilweise erfüllt & 1 \\ \hline
& Keine Doku & 0 \\ \hline
Swagger & Swagger yaml oder json file vorhanden, sowie Swagger UI zum ausprobieren, alle Beispiele und ggfs Auth./Tokens in Swagger UI funktionieren & 2 \\ \hline
& Swagger yaml file oder json vorhanden, aber keine Swagger UI oder andere Möglichkeit zum ausprobieren & 1 \\ \hline
& Keine Doku/ Möglichkeit zum Testen & 0 \\ \hline
\end{tabular}
\caption{Bewertungsschema Dokumentation}
\label{documentation}
\end{center}
\end{table}

\subsection{API - Spezifikationen}
\subsubsection{Spezifikationsanalyse \& Analysetools}

Die gestellte Aufgabe werden wir in der gestellten Form nicht lösen. Begründung: Die Analyse der Struktur und Elemente einer WSDL, OpenAPI-Spezifikation oder eines GraphQL-Schemas kann evtl. akademisch interessant sein. Eine (wie hier geforderte) rein metrische Auswertung der Struktur oder der eingesetzten Elemente in einer REST API-Spezifikation ist in der Praxis aber nicht zielführend. Entwickler sind vielmehr daran interessiert, wie einfach es ist, mit der API zu arbeiten, welche Funktionen sie bereitstellt und welche Datenformate sie unterstützt. \\
Auswahlkriterien sind somit nicht aus Metriken generierte Zahlen, sondern dass die API gut dokumentiert ist, eine klare und konsistente Architektur aufweist und die verwendeten Datenformate den Anforderungen des Projekts entsprechen. Auch Aspekte wie Performance, Skalierbarkeit und Sicherheit spielen eine wichtige Rolle. \\
Statt einer metrischen Auswertung kann es in der Praxis sinnvoller sein, Tools wie Swagger Hub oder Postman zu verwenden, um eine REST API auszuprobieren und ihre Funktionalität zu testen. Diese Tools bieten eine interaktive Schnittstelle zum Testen von API-Endpunkten, zur Überprüfung von Parametern und zur Anzeige von Ergebnissen. Auf diese Weise können Entwickler schnell und einfach herausfinden, ob eine API für ihre Zwecke geeignet ist und wie sie mit ihr interagieren können. \\
Wir werden deshalb Screenshots der ``Auswertungen'', wie sie mit diesen Tools stattfinden, für Swagger Hub und Postman, sowie Mockoon, bereitstellen, jedoch auf die zwangsläufige Redundanz beim ``Vergleich'' von 5 Services verzichten (5 Screenshots sind es trotzdem :-) )\footnote{Lachende Smileys lösen aufgrund des fröhlichen Gesichts das Feuern von Spiegelneuronen aus. Die in der Folge ausgeschütteten Hormone und Neurotransmitter erhöhen u.a. die Konzentration. Dies und nichts anderes wollen wir hier, wissenschaftlich fundiert, erreichen.\cite{wiki-spiegel}}. Wir haben uns für REST entschieden, weil es von 89\% der Entwickler verwendet wird, gefolgt von Webhooks (35\%), SOAP (34\%) und GraphQL (34\%).\footnote{Vgl. \cite{api-postman}} Die Beispiele nutzen jeweils die Spezifikation der Autobahn API.

\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/apispecs1.png}
  \caption{Ansicht in Swagger Hub nach Import einer Open API Spezifikation (json oder yaml). Ähnlich zur Swagger UI sind alle Routen, Parameter, Datenmodelle und Ressourcen gut visualisiert und können ausprobiert werden. Die API kann zudem durch NoCode Tools erweitert und verändert werden und anschließend sowohl die Dokumentation, als auch SourceCode für die meisten gängigen Sprachen exportiert werden.}
  \label{apispecs1}
\end{figure}

\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/apispecs2.png}
  \caption{Die in Abb.\ref{apispecs1} erwähnte Möglichkeit des Exports der Dokumentation, hier am Beispiel statischer HTML Files}
  \label{apispecs2}
\end{figure}

\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/apispecs4.png}
  \caption{Ansicht in Mockoon (Client) nach Import der json/yaml Spezifikation. Die API kann hervorragend visuell analysiert werden. Natürlich ist auch eine Anpassung möglich und Rückgaben können auf vielerlei Weisen gemockt werden, so dass z.B. für die Cliententwicklung gegen diese spezifische API, schnell und ohne Zugriff auf produktive Ressourcen, getestet werden kann.}
  \label{apispecs4}
\end{figure}

\begin{figure}[H]
\centering
  \includegraphics[width=250px]{images/apispecs3.png}
  \caption{Beispiel der in der Autobahn API Spezifikation dokumentierten Rückgabecodes für die entsprechende Route. Diese können sofort genutzt werden, über logische Verknüpfungen dynamisch zurückgegeben, gelöscht und erweitert werden. Auch eine künstliche Verzögerung des Response ist möglich.}
  \label{apispecs3}
\end{figure}

\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/apispecs5.png}
  \caption{Analog zu Swagger Hub und Mockoon hier die Ansicht in Postman nach Import der Spezifikationsdatei. Die Ansicht ähnelt den beiden anderen, jedoch bietet Postman zusätzlich viele weitere Features zur Analyse, Dokumentation, Monitoring, Entwicklung und Deployment eigener APIs.}
  \label{apispecs5}
\end{figure}

\subsubsection{Einschränkungen und Alternativen}

Die Fragen (Welche Informationen fehlen bei der gewählten Spezifikationen?, Recherchieren Sie nach alternativen Beschreibungsformen?) sind ähnlich praxisfern. Kein Mensch käme doch auf die Idee die verwendete REST-Schnittstelle von der vorhandenen Spezifikation abhängig zu machen. Verfügbarkeit, Preis, Skalierbarkeit, Performanz, Sicherheit etc. sind alles ausschlaggebende Kriterien - sowie natürlich, DASS die Schnittstelle gut dokumentiert ist (s. auch Abb.\ref{stateofapiobstaclesconsumtion}). Womit ist dann eher zweitrangig. 

\begin{figure}[H]
\centering
  \includegraphics[width=350px]{images/stateofapiobstaclesconsumtion.png}
  \caption{Häufigste Hindernisse bei der Verwendung von APIs\protect\footnote{\cite{api-postman}}}
  \label{stateofapiobstaclesconsumtion}
\end{figure}

Auch welche Informationen ``fehlen'' ist zwar nicht egal, aber insofern nicht zu beantworten, weil die notwendigen Informationen vom Usecase abhängen. Bezüglich der Funktionsweise lässt sich nur sagen: Spezifikation als Datei oder Link bereitstellen - ausprobieren - fertig. Die Tools unterscheiden sich hinsichtlich des Umfangs und der Komplexität, funktionieren aber in Grundzügen alle gleich: Sie visualisieren und ordnen die von der API bereitgestellten Funktionen. Schließlich ist in Bezug auf REST der Markt zwischen Json Schema und Swagger/Open API aufgeteilt (Graph QL: 34\%, WSDL: 26\%):\footnote{Vgl. \cite{api-postman}}
\begin{formal}
``We also asked folks which API specifications they use and love. JSON Schema was by far the most popular choice, used by 72\% of respondents. The next most popular were Swagger 2.0 (55\%) and OpenAPI 3.x (39\%)''
\end{formal}

Deshalb erfolgt an dieser Stelle keine systematische Analyse, sondern lediglich ein Vergleich zwischen den beiden (Swagger und Open API haben fast einen identischen Funktionsumfang und werden hier zusammengefasst) und anschließend einige ergänzende Screenshots der am häufigsten eingesetzten Tools Swagger Hub und Postman (Abb.\ref{stateofapi2}) und ergänzend ein von uns gern eingesetztes Tool (Mockoon) - sowie ein Hinweis auf die Möglichkeit der automatisierten ``Analyse'' mit Postman Flows.


\begin{figure}[H]
\centering
  \includegraphics[width=350px]{images/stateofapi2.png}
  \caption{Beliebteste Tools und Plattformen für die Arbeit mit APIs\protect\footnote{\cite{api-postman}} (Disclaimer: Die Umfrage stammt von Postman selbst)}
  \label{stateofapi2}
\end{figure}


\begin{table}[H]
\centering
\begin{tabular}{|L{4cm}|L{2cm}|L{2cm}|}
\hline
\textbf{Funktion} & \textbf{JSON Schema} & \textbf{Swagger 2.0/OpenAPI 3.0} \\ \hline
Schema-Definitionssprache & Ja & Ja \\ \hline
API-Beschreibung & Nein & Ja \\ \hline
API-Tests & Nein & Ja \\ \hline
API-Design & Nein & Ja \\ \hline
API-Visualisierung & Nein & Ja \\ \hline
API-Mocking & Nein & Ja \\ \hline
Beispielantworten & Nein & Ja \\ \hline
Beispielanfragen & Nein & Ja \\ \hline
Versionierung & Nein & Ja \\ \hline
Wiederverwendbare Komponenten & Nein & Ja \\ \hline
Sicherheitsdefinitionen & Nein & Ja \\ \hline
Unterstützung von Aufzählungen & Ja & Ja \\ \hline
\end{tabular}
\caption{Hauptunterschiede zwischen JSON Schema und Swagger 2.0/ OpenAPI 3.0}
\label{table:api-specs}
\end{table}

\begin{lstlisting}[language=Java,frame=single,caption=Testscript in Postman zum rekursiven Auslesen der zurückgegeben Objekte (distinct keys)\, die Ergebnisse können dann in Flows visualisiert werden\, s. Abb.\ref{flows},label=flowsscript]
pm.test("Status test", function() {
    let keys = [];

    function countKeys(obj) {
        Object.keys(obj).forEach(key => {
            if (!keys.includes(key)) {
                keys.push(key);
            }
            if (typeof obj[key] === 'object' && obj[key] !== null) {
                countKeys(obj[key]);
            }
        });
    }
    try {
        const rootKey = Object.keys(pm.response.json())[0];
        const root = pm.response.json()[rootKey][0];
        if (root) {
            countKeys(root);
            console.log(keys.length);
            pm.test(keys.length, function() {
                pm.expect(true).to.eql(true);
            });

        } else {
            console.log("Root element not found.");
        }
    } catch (error) {}

    pm.expect(true).to.eql(true);
});
\end{lstlisting}


\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/postmanflows.png}
  \caption{Postman LowCode Tool ``Flows'', hier ein prototypisches Beispiel zur Nutzung für die Analyse: Der Abruf von 2 Resourcen der Autobahn API setzt einen Inputparameter voraus (Autobahnnummer), welcher im Response des ersten request enthalten ist. Der Aufruf triggert den o.g. Test und zählt rekursiv die Anzahl der eindeutigen Bezeichner. Natürlich könnten Informationen wie die Tiefe, Größe der Objekte etc. einfach hinzugefügt werden. Abschließend wird die Zahl für jeden Request ausgegeben. Auch hier wäre es durch integrierte Blöcke für statistische Auswertungen einfach umzusetzen, die Zahlen in einem Array festzuhalten und am Ende z.B. ein Balkendiagramm zu erzeugen. Da Low Code hier mit JS verknüpft werden kann und mehrere API Spezifikationen in einer ``Collection'' zusammengefasst werden können, wäre es zudem möglich iterativ alle Routen aller APIs abzufragen und automatisiert zu dokumentieren. Wir haben bereits erläutert warum wie dies nicht gemacht haben.}
  \label{flows}
\end{figure}

\newpage
\section{Übung 3b: Entwicklung eigener Service-Angebote}
\subsection{Möglichkeiten für Implementierung und Deployment}
\subsubsection{Analyse der Möglichkeiten}

Nach eingehender Internetrecherche wurden einige Werkzeuge zur Implementierung und Deployment von APIs zusammengetragen. Zur besseren Einordnung dieser sind Eigenschaften wie Scope und Typ sowie falls vorhanden Laufzeitanforderungen aufgeführt. 

\begin{table}[h]
\centering
\begin{tabular}{|L{4cm}|L{3cm}|L{2cm}|L{2cm}|}
\hline
\textbf{Plattform / Service} & \textbf{Scope} & \textbf{Typ} & \textbf{Laufzeit} \\ \hline
AWS Lamda mit AWS API Gateway & Implementierung, Deployment & SaaS & - \\ \hline
ApiGee & Implementierung, Deployment & SaaS & - \\ \hline
Postman Api Builder & Implementierung & SaaS & - \\ \hline
Firebase & Implementierung, Deployment & SaaS & - \\ \hline
Swagger Hub & Deployment & SaaS & - \\ \hline
Cloudflare Workers & Deployment & FaaS & - \\ \hline
Supabase & Implementierung, Deployment & PaaS & - \\ \hline
AWS Amplify & Deployment & PaaS & - \\ \hline
AWS ECS & Deployment & IaaS & - \\ \hline
Swagger Codegen & Implementierung & Executable & Java \\ \hline
Apicurio Studio & Implementierung & Executable & Java \\ \hline
ASP.NET & Implementierung & Framework & C\# \\ \hline
express.js & Implementierung & Framework & JS \\ \hline
Flask & Implementierung & Framework & Python \\ \hline
Spring Boot & Implementierung & Framework & Java \\ \hline
Ruby on Rails & Implementierung & Framework & Ruby \\ \hline
\end{tabular}
\caption{Übersicht über verschiedene Plattformen und Services für die Implementierung, Deployment und Nutzung von APIs.}
\label{api-platforms}
\end{table}


\subsubsection{Analytischer Vergleich der Möglichkeiten}

Im Folgenden werden ausgewählte der im vorigen Abschnitt identifizierten Implementierungs- und Deploymentmöglichkeiten mittels eines Bewertungsschemas verglichen. Die ausgewählten tools stehen exemplarisch für jeweils eine Implementierungs- oder Deploymentart.

\paragraph{Implementierung} \mbox{} \\
Das der Bewertung verschiedener Implementierungsarten zugehörige Schema beinhaltet die Kriterien Komplexität der Implementierung, Komplexität der OpenApi-Spezifikationserstellung, Güte der Dokumentation, Popularität, Kosten und Geschwindigkeit. Zur Bewertung der Implementierungskomplexität werden die Implementierungen der gleichen Api verglichen. Dazu wird die künstliche Intelligenz ChatGPT genutzt. Diese bekommt pro Implementierungsart die gleiche Aufforderung, welche wie folgt aussieht: 
\begin{formal}
Implement a rest api with one endpoint named /items. This endpoint should return all columns of the mysql database table item and should be able to response the http-codes 200, 404 and 500. Do so using the shortest possible way in {Implementierungsart}.
\end{formal}

Die Ergebnisse wurden dann auf die Herkunft der nötigen libraries sowie die Anzahl der Funktionaufrufe untersucht. Zur Bewertung der Komplexität der OpenApi Spezifikationserstellung wurde recherchiert, ob eine Spezifikationserstellung überhaupt möglich und wenn möglich ohne externe Hilfsmittel/Libraries möglich ist. Außerdem wurde berücksichtigt, ob die Erstellung automatisch oder manuell erfolgt. Zur effektiven Entwicklung von Software sind umfangreiche, verständliche und vor allem aktuelle Dokumentationen von großer Bedeutung. Aufgrund dessen ist auch die Dokumentationsgüte teil des Bewertungsschemas. Hier fließen die Übersichtlichkeit, der Umfang, die Aktualität und die Verständlichkeit ein. Dabei gilt zu beachten, dass diese Bewertungen nicht objektiv messbar sind und daher subjektiv bewertet wurden. Außerdem wurde die Popularität mittels Google Trends bestimmt. Die Geschwindigkeit wurde anhand von Benchmarks gerankt. Ein weiteres sehr wichtiges Kriterium zu Auswahl der Entwicklungswerkzeuge ist die Preisstruktur dieser, weshalb diese ebenfalls aufgeführt ist.

\begin{lstlisting}[language=Java,frame=single,caption=Implementierung in Java,label=toml]
import java.sql.ResultSet;
import java.sql.SQLException;
import java.util.List;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.jdbc.core.JdbcTemplate;
import org.springframework.jdbc.core.RowMapper;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping("/items")
public class ItemController {

    public static void main(String[] args) {
        SpringApplication.run(Main.class, args); 
    }

    @Autowired
    private JdbcTemplate jdbcTemplate;

    @GetMapping
    public ResponseEntity<List<Item>> getAllItems() {
        try {
            List<Item> items = jdbcTemplate.query(
                    "SELECT * FROM item",
                    new RowMapper<Item>() {
                        public Item mapRow(ResultSet rs, int rowNum) throws SQLException {
                            Item item = new Item();
                            item.setId(rs.getLong("id"));
                            item.setName(rs.getString("name"));
                            item.setDescription(rs.getString("description"));
                            item.setPrice(rs.getDouble("price"));
                            return item;
                        }
                    });
            if (items.isEmpty()) {
                return new ResponseEntity<>(HttpStatus.NOT_FOUND);
            }
            return new ResponseEntity<>(items, HttpStatus.OK);
        } catch (Exception e) {
            return new ResponseEntity<>(null, HttpStatus.INTERNAL_SERVER_ERROR);
        }
    }

    public static class Item {
        private long id;
        private String name;
        private String description;
        private double price;

        public long getId() {
            return id;
        }

        public void setId(long id) {
            this.id = id;
        }

        public String getName() {
            return name;
        }

        public void setName(String name) {
            this.name = name;
        }

        public String getDescription() {
            return description;
        }

        public void setDescription(String description) {
            this.description = description;
        }

        public double getPrice() {
            return price;
        }

        public void setPrice(double price) {
            this.price = price;
        }
    }
}

\end{lstlisting}

\begin{lstlisting}[language=Python,frame=single,caption=Implementierung in python,label=toml]
from flask import Flask, jsonify
from flask_mysqldb import MySQL

app = Flask(__name__)
app.config['MYSQL_HOST'] = 'localhost'
app.config['MYSQL_USER'] = 'username'
app.config['MYSQL_PASSWORD'] = 'password'
app.config['MYSQL_DB'] = 'database'
mysql = MySQL(app)

@app.route('/items')
def get_items():
    cur = mysql.connection.cursor()
    cur.execute("SELECT * FROM item")
    data = cur.fetchall()
    if data:
        return jsonify(data), 200
    else:
        return jsonify({"message": "No items found"}), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({"message": "Internal server error"}), 500

if __name__ == '__main__':
    app.run(debug=True)
\end{lstlisting}

\begin{lstlisting}[language=Java,frame=single,caption=Implementierung in C\#,label=toml]
using Microsoft.AspNetCore.Builder;
using Microsoft.AspNetCore.Http;
using Microsoft.Extensions.DependencyInjection;
using Dapper;
using MySql.Data.MySqlClient;
using System;
using System.Linq;

var builder = WebApplication.CreateBuilder(args);

builder.Services.AddSingleton<MySqlConnection>(sp =>
    new MySqlConnection(builder.Configuration.GetConnectionString("DefaultConnection")));

var app = builder.Build();

app.MapGet("/items", async (HttpContext httpContext, MySqlConnection connection) =>
{
    try
    {
        var items = (await connection.QueryAsync<Item>("SELECT * FROM Items")).ToList();
        if (items.Count == 0)
        {
            return Results.NotFound();
        }
        return Results.Ok(items);
    }
    catch (Exception ex)
    {
        Console.Error.WriteLine(ex);
        return Results.StatusCode(StatusCodes.Status500InternalServerError);
    }
});

app.Run();

public record Item(int Id, string Name, string Description, decimal Price, DateTime CreatedAt);
\end{lstlisting}

\newpage
\begin{table}[H]
\centering
\begin{minipage}{\textwidth} 
\begin{tabular}{|L{2.5cm}|L{3cm}|L{5.5cm}|L{3cm}|}
\hline
Kriterium & Unterkategorie & Bewertungen & Quellen \\ \hline
Komplexität der Implementierung & notwendige Hilfsmittel/Libraries & 1: keine externen Hilfsmittel/Libraries nötig \newline 0: externe Hilfsmittel/Libraries nötig &  \\ \cline{2-4}   
& Anzahl der notwendigen Schritte/Funktionsaufrufe & 0: mehr als der Durchschnitt der anderen \newline 1: durchschnittlich \newline 2: weniger als der Durchschnitt der anderen &  \\ \hline
OpenAPI-Spezifikation & Integration & 2: out of the box \newline 1: Drittanbieter library \newline 0: nicht möglich & Spring: \footnote{https://spring.io/} \newline Flask: \footnote{https://flask.palletsprojects.com/en/2.1.x/} \newline .NET: \footnote{https://dotnet.microsoft.com/} \newline Postman: \footnote{https://www.postman.com/} \\ \hline
Implementierung & & 2: automatisch \newline 1: manuell &  \\ \hline
Dokumentation & Übersichtlichkeit (logische Untergliederung) & 1: übersichtlich \newline 0: unübersichtlich & Spring: \footnote{https://spring.io/} \newline Flask: \footnote{https://flask.palletsprojects.com/en/2.1.x/} \newline .NET: \footnote{https://dotnet.microsoft.com/} \newline Postman: \footnote{https://www.postman.com/} \\ \hline
Umfang & & 1: vollumfänglich \newline 0: unvollständig &  \\ \hline
Aktualität & & 1: aktuell \newline 0: (teils) veraltet &  \\ \hline
Verständnis (ggf. mit Beispielen) & & 1: gut verständlich \newline 0: nicht gut verständlich &  \\ \hline
Popularität & - & Rangfolge entsprechend Google Trends (0-3) & \footnote{https://trends.google.com/trends/explore?q=swagger\%20ui,postman,insomnia\&geo=US} \\ \hline
Geschwindigkeit & - & Rangfolge entsprechend TechEmpower Benchmark (0-2) & \footnote{https://www.techempower.com/benchmarks/} \\ \hline
Skalierbarkeit & Replizierbarkeit & 1: möglich \newline 0: nicht möglich & Glassfish\footnote{https://docs.oracle.com/cd/E19182-01/821-0915/jbi\_cluster-create\_t/index.html} \\ \cline{2-4}   
& Loadbalancing (Clustering) & 1: möglich \newline 0: nicht möglich &  \\ \cline{2-4}
& Effizienz & 1: geringer Ressourcenverbrauch \newline 0: hoher Ressourcenverbrauch &  \\ \hline
Continuous Deployment & - & 2: ohne Downtime möglich \newline 1: mit Downtime möglich \newline 0: nicht möglich & \\ \hline
\end{tabular}
\end{minipage}
\label{tab:bewertungskriterien}
\caption{Bewertungskriterien für API-Testtools}
\end{table}%
\newpage

\paragraph{Deployment} \mbox{} \\
Ähnlich dem Vergleich der Implementierungsmöglichkeiten wurden auch für den Deploymentmöglichkeiten-Vergleich repräsentative Vertreter für die drei verbreitetsten Arten Application Server, Cloud Server und Container gewählt. Diese wurden bezüglich der Skalierbarkeit und der Continuous-Deployment-Fähigkeit verglichen. Dabei wurde zur Bewertung der Skalierbarkeit die Replizierbarkeit und das Möglichkeit von Loadbalancing sowie die Effizienz herangezugen um so die Fähigkeit zum vertikalem Skalieren abzubilden. Die Continuous Deployment Fähigkeit wird damit bestimmt, ob dies grundsätzlich möglich ist und wenn ja, mit oder ohne Server Downtime. \\



\begin{figure}[H]
\centering
  \includegraphics[width=350px]{images/stateofapideploymentcontainers.png}
  \caption{Häufigste Deploymentformen von REST APIs\protect\footnote{\cite{api-postman}}}
  \label{stateofapideploymentcontainers}
\end{figure}


\begin{tabular}{|L{2cm}|L{3.2cm}|L{1.5cm}|L{1.5cm}|L{1.5cm}|L{1.5cm}|L{1.5cm}|}
\hline
& Kriterium & Aws Api Gateway & Azure Api Management & Linode & AWS EC2 & On Premise \\ \hline
Flexibilität Entwicklung & mehrere Sprachen & + & + & + & + & + \\ 
& vorgegebene Libraries/Frameworks & + & + & + & + & + \\ 
& Api-Dokumentaion/-Spezifikation & + & + & + & + & + \\ \hline
Flexibilität Deployment & Integration in CD Pipelines & / & + & + & + & + \\ 
& Restriktionen & ? & ? & + & + & + \\ 
& verschiedene Umgebungen (Test/Production) & + & + & + & + & + \\ 
& parallele Versionen möglich & + & + & + & + & + \\ \hline
Skalierbarkeit & Containerisierung möglich & ? & + & / & / & / \\ 
Kosten & initial & + & + & + & + & - \\ 
& laufend & - & - & / & / & / \\ \hline
Abhängigkeiten & vorgeschriebene Libraries/Frameworks & + & + & + & + & + \\ 
& Abhängigkeit von Anbieter selbst & - & - & - & - & + \\ 
& Laufzeitumgebung & / & / & - & / & + \\ \hline
\end{tabular}

\subsection{Entwicklung}
\subsubsection{Rahmenbedingungen}
 
Für eine nachvollziehbare Argumentation, warum der eingesetzte Toolstack verwendet wurde und welche Laufzeitumgebung und Art des Deployments als angebracht eingeschätzt wurde, sollen zunächst kurz die Anforderungen an die Anwendung dargestellt werden. Diese sind zwar ``simuliert'', jedoch (in sehr oberflächlicher Form) an möglichen realen Anforderungen angelehnt. Da die nicht-funktionalen Anforderungen hier eher die Argumentationsgrundlage bilden, stehen diese im Fokus - funktionale Anforderungen sollten nur in Ausnahmefällen eine Determinante für Techstack und Deployment sein.  \\
Überlegungen, welche eine prototypische Umsetzung im gegebenen Rahmen sprengen würden, werden bewusst außer acht gelassen. Dazu gehören: ggfs. initial höhere Entwicklungskosten, verfügbare (Entwicklungs)ressourcen und Skillset der Beteiligten, architektonische Überlegungen und der Einsatz bestimmter Design Patterns, sowie das Thema Tests. \\
Desweiteren halten wir eine Begründung, warum nun welche Entwicklungsumgebung eingesetzt wurde, nicht für sinnvoll. Welche IDE ein Entwickler verwendet, ob als Git nun Github, Gitlab oder Bitbucket verwendet wird und mit welchem Tool REST Endpunkte getestet werden ist entweder von den Vorlieben und Gewohnheiten des Einzelnen abhängig, oder durch Vorgaben des Arbeitgebers bestimmt (oder beides). Insofern beschränken wir uns bei diesen Punkten auf die Benennung der ``Werkzeuge'', ohne das Warum weiter zu vertiefen. Stattdessen wollen wir die aus unserer Sicht viel wichtigere Frage beantworten, warum für den genannten Usecase eine bestimmte Sprache, Bibliotheken und Deploymentszenarien gewählt wurden.
 
\paragraph{Anforderungen} \mbox{} \\

Funktionale Anforderungen:
\begin{itemize}
\item Anzeige von Basisinformationen zu Coderepositories (Autor, Sprache, Forks, Commits), welche über eine REST API abgerufen werden
\item Löschen vorhandener, Hinzufügen neuer und Ändern vorhandener Repositories (Client)
\item Persistierung der Änderungen in einer Datenbank
\item Bereitstellung als Webapp
\end{itemize}

Nicht-funktionale Anforderungen: 
\begin{itemize}
\item unterdurchschnittlich geringe TCO durch:
\begin{itemize}
\item hohe Performanz und geringen Footprint bei der Hardwarenutzung
\item geringe Wartungskosten
\item einfache Verwaltung der Abhängigkeiten
\item einfaches Deployment
\end{itemize}
\item gute Skalierbarkeit
\item hohes Level an Sicherheit
\item volle Flexibilität hinsichtlich der Laufzeitumgebung
\item DB Typ möglichst offen
\end{itemize}



\paragraph{Verwendete Sprache(n)} \mbox{} \\

Client und REST API sollen in Rust geschrieben werden, auch die verwendete Datenbank (Surreal DB) ist in Rust geschrieben. Rust ist eine multi-paradigmatische, noch recht junge (2015) Programmiersprache, die auf konzeptioneller Ebene einige Besonderheiten aufweist. Im Folgenden werden einige dieser Besonderheiten erläutert:
\begin{itemize}
\item Memory-Safety und Thread-Safety: Rust erreicht dies durch eine strenge Typisierung und durch Speicherzugriffsregeln, die sicherstellen, dass Speicher nur dann gelesen oder geschrieben werden kann, wenn es korrekt und sicher ist. Dies wird durch die Borrowing- und Ownership-Konzepte erreicht, die den Zugriff auf den Speicher in Rust stark reglementieren. Mit diesen Regeln ist es möglich, Memory-Safety-Garantien zu erzwingen, ohne dass ein Garbage-Collector erforderlich ist, aber auch ohne den in C und C++ verwendeten Ansatz der manuellen Speicherkontrolle.
\item Laufzeitstabilität: Rust ist dafür bekannt, Laufzeitfehler quasi auszuschließen (von daher der Name - einmal ausgerollt kann die Anwendung vor ich hin rosten). Dies wird durch eine Kombination aus verschiedenen Techniken erreicht, darunter die bereits erwähnten Konzepte, den Verzicht auf nulls und einen in vielen Fällen funktionalen Programmierstil. Ausschlaggebend für die hohe Laufzeitstabilität ist zudem der tiefgreifende Compiler, der bereits bei der Übersetzung des Codes umfangreiche Fehlerprüfungen durchführt. Dadurch werden viele potenzielle Fehlerquellen bereits im Vorfeld erkannt und beseitigt.
\item Gute Dokumentation: Die Gesamtdokumentation, insbesondere das Rust Book, aber auch die Dokumentation der einzelnen Bibliotheken, bietet sowohl Einsteigern als auch erfahrenen Entwicklern Hilfestellungen, um die Sprache zu erlernen und ihre Fähigkeiten zu verbessern.
\item Management von Abhängigkeiten: das Management von Abhängigkeiten durch das Cargo-Build-System garantiert eine Kompatibilität der (transitiven) Abhängigkeiten und ein replizierbares Kompilat/Binary, sowie durch SemVer eine einfache Verwaltung der Abhängigkeiten
\item Rust hat eine schnell wachsende Community und wird von immer mehr Unternehmen für die (Re)implementierung kritischer Komponenten eingesetzt (z.B. npm, Cloudflare und AWS Lambda). Teile des Android Kernels, sowie des Linuxkernels und neuerdings auch Systemkomponenten in Windows werden in Rust neu geschrieben. Diese Entwicklung deutet auf eine stabile Zukunft sowohl hinsichtlich technischem Support, also auch wachsender Entwicklerressourcen hin - ein gewichtiges Argument bei der Businessentscheidung für eine Sprache.
\end{itemize}

\paragraph{Komponenten} \mbox{} \\
\subparagraph{REST API} \mbox{} \\
Aus der Beschreibung in Verbindung mit den nicht funktionalen Anforderungen lässt sich die Entscheidung für Rust für die systemkritischen (REST API) Komponenten ableiten. Sicherheit, Stabilität, eine hohe Flexibilität der Laufzeitumgebungen, Performanz (s. auch Abb.\ref{fig:apibenchmark} sowie voraussichtlich geringe TOC sind bei einer Umsetzung mit Rust wahrscheinlicher als in den meisten anderen Sprachen. Microsoft führt beispielsweise einen großen Teil der Schwachstellen auf fehlerhafte Speicherverwaltung zurück, dieses Risiko wird durch die garantierte Memory-Safety minimiert:
\begin{formal}
``Microsoft revealed at a conference in 2019 that from 2006 to 2018 70 percent of their vulnerabilities were due to memory safety issues. Google also found a similar percentage of memory safety vulnerabilities over several years in Chrome.''\footnote{https://media.defense.gov/2022/Nov/10/2003112742/-1/-1/0/CSI\_SOFTWARE\_MEMORY\_SAFETY.PDF}
\end{formal}

Für Rust im Backend spricht auch die vielfältige Auswahl von ausgereiften und hochperformanten Bibliotheken und Frameworks für die Backendentwicklung (Abb.\ref{apibenchmark}). 

\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/score3.png}
  \caption{Benchmark Backend Webframeworks}
  \label{apibenchmark}
\end{figure}

Ein Nachteil (der auch auf den Rest zutrifft, deshalb wird er nur einmal benannt) kann zudem sein, dass Rust noch eine sehr junge Sprache ist. Die Verfügbarkeit (insbesondere erfahrener) Entwickler ist sehr überschaubar und dürfte sich zudem in höheren Salären niederschlagen. Andererseits ist Rust seit sieben Jahren in Folge (Abb.\ref{devsurvey}) die beliebteste Sprache unter Entwicklern, sowie diejenige, welche   auf Platz 1 der Sprachen steht, die Entwickler neu lernen wollen (Abb.\ref{surveywanted}). Das schlägt sich in einer schnell wachsenden Community nieder und dürfte langfristig auch die Verfügbarkeit von Entwicklern erhöhen. Dennoch birgt die Entscheidung im Gegensatz zu einer für eine ``etabliertere Sprache'' aus Personalsicht ein gewisses Risiko.

\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/devsurvey.png}
  \caption{Top 10 Programming, scripting, and markup languages (Most loved and dreaded) im Stackoverflow Developersurvey 2022}
  \label{devsurvey}
\end{figure}

\begin{figure}[H]
\centering
  \includegraphics[width=200px]{images/surveywanted.png}
  \caption{Top 10 Programming, scripting, and markup languages (Most wanted) im Stackoverflow Developersurvey 2022}
  \label{surveywanted}
\end{figure}

\subparagraph{Client} \mbox{} \\
Die Entscheidung auch das Frontend in Rust zu implementieren war hingegen eher experimenteller Natur und würde - auch aufgrund der teils noch nicht ausgereiften Frameworks - in einer realen Situation vermutlich anders ausfallen. Dennoch soll die Entscheidung an dieser Stelle kurz begründet werden. \\

Da Rust problemlos in Maschinencode als auch Webassembly (Entwicklung 2018) kompiliert werden kann, verzichten die meisten Webframeworks, die in Rust geschrieben sind, komplett auf Javascript. Systemnahe Sprachen, typischerweise Assembler, C++ oder Rust, aber auch interpretierte Sprachen wie C\# können mit der Laufzeitumgebung Webassembly in bytecode kompiliert werden, welcher plattformunabhängig und extrem schnell im Browser, zunehmend aber auch auf verteilten Systemen ausgeführt wird. Das verwendete Framework Perseus zeichnet sich durch seinen Reactive Ansatz (ähnlich Svelte oder Solid.js), sowie eine sehr hohe Performanz aus (s. auch Abb.\ref{fig:clientbenchmark}. Zudem ist auch das Deployment für Mobiles und Desktoplattformen möglich. Es unterstützt SSR (Serverside Rendering) und benötigt kein Virtual DOM (was i.d.R. durch den zusätzlichen Overhead die Performance etwas drückt)\footnote{https://github.com/flosse/rust-web-framework-comparison}. \\

\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/bm.png}
  \caption{Benchmark Frontend Webframeworks. Perseus wurde nicht getestet, hat aber in Einzelbenchmarks etwas bessere Werte als das zugrundeliegende Sycamore (hier zu sehen)}
  \label{fig:clientbenchmark}
\end{figure}


Zu bedenkende Nachteile, insbesondere im produktiven Einsatz, könnte beim Frontendframework die im Gegensatz zu den Backendframeworks die fehlende Maturität sein. Zudem kommt hier durch den Einsatz von Webassembly eine weitere spezifische Anforderung an die Fähigkeiten der Entwickler hinzu, was die Verfügbarkeit weiter einschränken dürfte.

\subparagraph{Datenbank} \mbox{} \\
Als Datenbanksystem wurde Surreal DB ausgesucht, weil hier die Bandbreite der Möglichkeiten am höchsten ist. Insbesondere die Nutzung sowohl als relationale und nicht relationale Datenbank, die integrierte, sichere REST Schnittstelle und die hohe Performanz, haben in Bezug auf die genannten Anforderungen zu der Entscheidung geführt. Weitere Vorteile, die zur Auswahl geführt haben:
\begin{itemize}
\item Single-node oder verteilt
\item strukturierte und unstrukturierte Daten
\item GraphQL, REST, WebSockets als Schnittstellen (wir nutzen REST)
\item Real time sync
\item flexibles modelling (relational/ nicht relational, keine joins)
\item Web-native access (JWT, OAuth, Basic)
\item open source
\item flexible Speichertechnologien (in memory, kv, document)
\end{itemize}

Zudem bietet das System hinsichtlich der Zugänglichkeit durch die Abfragesprache SurrealQL, welche stark an SQL angelehnt ist, es jedoch z.B. wie in Listing \ref{surrealsyntax} zu sehen ist, um Funktionen wie die Integration von Javascript erweitert.

\begin{lstlisting}[language=SQL,frame=single,caption=SQL ähnliche Syntax in Surreal DB,label=surrealsyntax]
INSERT INTO company {
	name: 'SurrealDB',
	founded: "2021-09-10",
	founders: [person:tobie, person:jaime],
	tags: ['big data', 'database']
};

CREATE user:test SET
	session_timeout = function() {
		return new Duration('1w');
	},
	best_friend = function() {
		return new Record('user', 'joanna');
	},
	identifier = function() {
		return new Uuid('03412258-988f-47cd-82db-549902cdaffe');
	};
\end{lstlisting}

Nachteil ist hier analog zu den anderen Komponenten die geringe Verbreitung. Andererseits wird der Ansatz der Nutzerfreundlichkeit (auch aufgrund der guten Dokumentation) für Entwickler u.E. so gut umgesetzt, dass eine sehr schnelle Einarbeitung im Gegensatz zu anderen DBMS möglich ist.

\paragraph{Eingesetzte Frameworks und Libraries} \mbox{} \\
Actix wurde aufgrund der guten Performanz (s. auch Abb.\ref{apibenchmark}), Dokumentation, Aktualität und Kompatibilität mit Concurrency ausgewählt. Sycamore (bzw. darauf aufbauend Perseus) aufgrund der Performanz und relativ weiten Verbreitung und somit guten Unterstützung aus der Entwicklercommunity. Utoipa für die Dokumentation mit OpenAPi/Swagger ist quasi alternativlos, ebenso Serde für den Umgang mit Json Objekten. Weitere, transitive Abhängigkeiten (die in Rust qua Architektur des Abhängigkeitenmanagements mit Traits und Crates sehr kleinteilig und quantitativ hoch sind) sind hier nicht dargestellt, können aber beispielhaft für die REST API der toml- Konfigurationsdatei entnommen werden.

\begin{table}[H]
\begin{center}
\begin{tabular}{| L{2.5cm} | L{2cm} | L{2cm} | L{2.9cm} | L{2.9cm} | }
\hline
Servicekom- ponente & Name & Version & Autor & Funktion \\ \hline
Client & sycamore & 0.8.1 & sycamore-rs & Webassembly Webframework  \\ \hline
Client & perseus & 0.4.0-rc.1 & framesurge &  Sycamore Erweiterung, ermöglicht Hot State reloading, i18n Support \\ \hline
Client, REST API & tokio & 1.0 & tokio & Concurrency (async main)  \\ \hline
Client, REST API & reqwest / reqwasm & 0.11.17 / 0.5.0 & Rust Foundation & HTTP Client (Standard und für Webassembly) \\ \hline
REST API & serde & 1.0.152 & Serde &  JSON (De)serialisierung  \\ \hline
REST API & actix-Web & 4 & actix & Webserver, Webframework  \\ \hline
REST API & utoipa & 3.3 & juhaka & Open API Doc Generation  \\ \hline
Datenbank & Surreal DB & 1.0.0-beta.9 & Tobie und Jaime Morgan Hitchcock & vollständiges DBMS und integrierter Server \\ \hline 
\end{tabular}
\caption{Verwendete, externe Abhängigkeiten}
\label{dependencies}
\end{center}
\end{table}

\begin{lstlisting}[language=SQL,frame=single,caption=cargo.toml Datei zur Organisation der Abhängigkeiten in Rust\, hier für die REST API,label=toml]
[package]
name = "rust-actix-surreal-rest-api"
version = "0.1.0"
edition = "2023"
authors = ["Hannes Roever"]

[dependencies]
actix-web = "4"
actix-cors = "*"
serde = {version = "1.0.152", features = ["derive"]}
serde_json = {version = "1.0.93"}
tokio = { version = "1", features = ["full"] }
mini-redis = "0.4"
env_logger = "0.10.0"
log = "0.4"
futures = "0.3"
utoipa = { features = ["actix_extras"] }
utoipa-swagger-ui = { features = ["actix-web"] }
chrono = "*"
reqwest = {features = ["json"]}
\end{lstlisting}

\begin{lstlisting}[language=SQL,frame=single,caption=cargo.toml Client,label=toml]
[package]
name = "perseus-website"
version = "0.1.0"
edition = "2023"
authors = ["Hannes Roever"]

[dependencies]
perseus = { version = "0.4.0-rc.1", features = [ "hydrate" ] }
sycamore = { version = "^0.8.1", features = ["suspense"] }
serde = "1.0.152"
serde_json = "1.0.93"
reqwest = {features = ["json"]}
# futures = "0.3"
chrono = "*"
dotenv = "0.15.0"

[target.'cfg(engine)'.dependencies]
tokio = { version = "1", features = [ "macros", "rt", "rt-multi-thread" ] }
perseus-axum = { version = "0.4.0-rc.1", features = [ "dflt-server" ] }

[target.'cfg(client)'.dependencies]
web-sys = { version = "0.3", features = [ "Storage" ] }
reqwasm = "0.5.0"
\end{lstlisting}

\paragraph{Konfiguration Entwicklungsumgebung} \mbox{} \\
Voraussetzung für die dargestellten Schritte ist, dass Docker bereits installiert ist (Docker Client auf Windows, Docker Engine auf Linux). Da dies, analog zum Vorhandensein einer geeigneten IDE oder eines Editors, zu den Basiswerkzeugen in der Entwicklung gehört, wird der allgemeine Installations- und Konfigurationsprozess nicht weiter ausgeführt (zumal er sich je nach OS auch unterscheidet und bestens dokumentiert ist).

\subparagraph{Datenbank} \mbox{} \\
Die Datenbank kann sehr unkompliziert als Docker-Container gestartet werden. Das entsprechende CLI Kommando bzw. der Inhalt und das Kommando zum Ausführen der docker-compose.yml sind in den Listings \ref{surrealdockerone}-\ref{surrealdockerthree} dargestellt. s sollte nur eine der Optionen genutzt werden. Anschließend läuft die Datenbank mit in-memory Option (weitere sind möglich) unter Port 8000 des localhost.

\begin{lstlisting}[language=SQL,frame=single,caption=CLI Command zum Starten des Datenbankcontainers,label=surrealdockerone]
docker run --rm --pull always -p 8000:8000 surrealdb/surrealdb:latest start
\end{lstlisting}

\begin{lstlisting}[language=SQL,frame=single,caption=Alternative mit docker-compose zum Starten des Datenbankcontainers,label=surrealdockertwo]
version: '3.8'
services:
  db:
    image: surrealdb/surrealdb:latest
    restart: always
    command: start --user root --pass root memory
    ports:
      - '8000:8000'
    volumes: 
      - db:/var/lib/surrealdb/data
volumes:
  db:
    driver: local
\end{lstlisting}

\begin{lstlisting}[language=bash,frame=single,caption=CLI Command zum Ausführen der docker-compose Datei. Das Kommando muss im Verzeichnis ausgeführt werden\, in dem die Datei liegt\, oder der Pfad der Datei über die flag --f spezifiziert werden,label=surrealdockerthree]
docker-compose up -d
\end{lstlisting}

\subparagraph{REST API} \mbox{} \\
Für die Entwicklung in Rust wird die Rust Toolchain benötigt (bestehend aus rustup, rustc und cargo). Die Installation erfolgt über die Kommandozeile oder für Windows mit einem Installer, welcher unter https://www.rust-lang.org/tools/install heruntergeladen werden kann. Ggfs. muss noch die ensprechende Umgebungsvariable gesetzt werden. Die Toolchain umfasst alle notwendigen Commandlinetools für die Kompilierung, Codeformatierung, Abruf von Dokumentation (ähnlich zu MAN Pages), Tests und Deployment. 

\begin{lstlisting}[language=bash,frame=single,caption=CLI Command zur Installation von Rust in Linux und macOS,label=rustinstallationone]
curl --proto '=https' --tlsv1.3 https://sh.rustup.rs -sSf | sh
\end{lstlisting}

Für die Erstellung eines neuen Projekts muss das Kommando cargo new projektname ausgeführt werden. Im entsprechenden Verzeichnis wird ein Ordner mit den Konfigfiles, main und Gitrepository angelegt. Die Bearbeitung des Codes kann mit einem einfachen Editor (z.B. Vim, Neovim, Emacs, Sublime, Nano), einem erweiterten Editor (VS Code) oder einer vollumfänglichen IDE (Intellij IDEA, CLion) vorgenommen werden. Wir nutzen IntelliJ und für die schnelle Bearbeitung, z.B. auf einem über SSH verbundenen Server, Nano. \\
Weitere Schritte sind nicht notwendig, die Abhängigkeiten können in der cargo.toml (s.a. Listing \ref{toml}) Datei hinzugefügt werden und werden beim nächsten Build, so noch nicht lokal vorhanden, automatisch gezogen und kompiliert. Mit cargo run (bauen, ausführen) bzw cargo build (bauen), fürs publishing mit --release flag, wird das Programm ausgeführt. 

\subparagraph{Client WebApp} \mbox{} \\
Um die Kompilierung in WASM zu ermöglichen sind zwei weitere, global bereitzustellende Abhängigkeiten notwendig, die Installation ist in Listing \ref{rustinstallationtwo} zu sehen.

\begin{lstlisting}[language=bash,frame=single,caption=CLI Command zur Installation der Laufzeitumgebung webassembly und des WASM-Buildtools Trunk für Rust,label=rustinstallationtwo]
rustup target add wasm32-unknown-unknown
cargo install --locked trunk
\end{lstlisting}

Der Start eines bereits erstellten Projektes kann mit trunk --serve durchgeführt werden, durch das Buildtool wird automatisch ein lokaler Webserver bereitgestellt. Perseus baut auf Sycamore auf und kann mit den Commands aus Listing \ref{perseusone} installiert und ausgeführt werden.

\begin{lstlisting}[language=bash,frame=single,caption=CLI Command zur Installation der Perseus CLI und Ausführung eines Projektes,label=perseusone]
cargo install perseus-cli
perseus serve -w
\end{lstlisting}

\paragraph{Deployment} \mbox{} \\
Das Deployment wird, dem Industriestandard folgend, als Containerlösung realisiert. Um den Rahmen nicht zu sprengen, haben wir uns für Docker (mit docker-compose) entschieden und auf einen Orchestrierungslayer, z.B. mit K8, verzichtet. Die physische Bereitstellung erfolgt bei einem IAAS Anbieter, aufgrund der Nutzung von Docker ist die Linux-Distribution zweitrangig - Debian oder Ubuntu als etablierte Serverdistros oder Alpine als Low-Footprint Distro sind naheliegende Optionen. Windows Server oder spezielle oder proprietäre Lösungen sind nicht notwendig und u.E. auch nicht sinnvoll, weil sie eine Abhängigkeit von einer bestimmten Firma bzw. Technologie schaffen. Zudem haben Umgebungen wie Java Application Server einen extrem hohen Overhead, den wir vermeiden wollen um die gesteckten Ziele nicht zu gefährden. 

\subsubsection{Umsetzung}

\paragraph{Design} \mbox{} \\

Der Ansatz folgt einem einfachen Client-Server Paradigma (Client, Serverbackend, Datenbank). In Abb. \ref{deploymentdiagramm} ist das auf Serviceebene und unter Einsatz von Containern aufgebaute Diagramm gezeigt. In den verschiedenen Phasen einer auf schnelle Deployments ausgerichteten, agilen Entwicklung sind die Bezüge zu den Sourcecoderepositories und einzelnen Phasen der Pipelines, sowie den Repositories (Registries) für die Artefakte dargestellt. Das Diagramm (eigene Quelle) wurde im Rahmen eines anderen Projekts für die Hochschule erstellt und wenn auch in diesem Kontext die Testphasen keine Rolle spielten, so stellt es doch aus High-Level Sicht gut die Zusammenhänge der zu entwickelnden Komponenten dar. \\
Weitere Überlegungen zum Design mussten up-front nicht erfolgen, Best Practices wie der Einsatz von Design Patterns und Clean Code Standards können während der Entwicklung eingesetzt werden und aufgrund der Einfachheit der Anforderungen würde eine ``Designphase'' wahrscheinlich länger dauern als die Entwicklung selbst und die Hälfte davon wird am Ende erfahrungsgemäß ohnehin verworfen. 

\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/deployment.png}
  \caption{Deploymentdiagramm}
  \label{deploymentdiagramm}
\end{figure}



\paragraph{Implementierung} \mbox{} \\
Die Implementierung soll für alle Bestandteile jeweils anhand kurzer Codeabschnitte erläutert werden. Der Fokus ist dabei themenbedingt auf die Komponenten beschränkt, die auf der Schnittstellenebene miteinander kommunizieren, welche jeweils die Boundary der jeweiligen Komponente bilden (also jeweils die REST-Schnittstelle zwischen Client und Backendserver, sowie Backendserver und Datenbank).

\subparagraph{Client (Hannes)} \mbox{} \\

\begin{lstlisting}[language=Java,frame=single,caption=Markup im Framework Perseus/Sycamore in Rust,label=clientone]
fn create_feature_card<G: Html>(cx: Scope<'_>, repos: Vec<Repository>) -> View<G> {
    let mut all = Vec::with_capacity(repos.capacity());
    for repo in repos.clone() {
        all.push(view! { cx,
            div(class = "card"){
                div(class = "feature-title"){ "Name: " (repo.name.clone()) ", erstellt am " (repo.created_at.clone()) }
                div(style= "display:flex;"){
                    div(class = "feature-text"){
                        p {"commits " (repo.commit_count.clone()) }
                        p {"forks " (repo.forks_count.clone()) }
                    }
                    div(class = "feature-text"){
                        p {"stars " (repo.stars_count.clone()) }
                        p {"pull requests " (repo.pull_requests.clone()) }
                    }
                    div(class = "feature-text"){
                        p {"watchers " (repo.watchers.clone()) }
                        p {"language " (repo.primary_language.clone()) }
                    }
                }
            }
        });
    }
    let markup = View:: new_fragment(all);
    markup
}
\end{lstlisting}

\begin{lstlisting}[language=Java,frame=single,caption=Aufruf des Get Endpunktes für die Repositories im Client,label=clienttwo]
#[engine_only_fn]
async fn get_build_state(
    _info: StateGeneratorInfo<()>,
) -> IndexPageState {

    let base_url = env::var("REST_URL").expect("No url env. variable found");
    let port = env::var("REST_PORT").expect("No port env. variable found");
    let url = format!("http://{}:{}/repositories", base_url, port);
    println!("{}", url);
    let client = reqwest::Client::new();
    let res =match client
        .get(url)
        .header(CONTENT_TYPE, "application/json")
        .header(ACCEPT, "application/json")
        .query(&[("timestamp", chrono::Utc::now().timestamp())])
        .send()
        .await {
        Ok(resp) => resp,
        Err(e) => {
            return IndexPageState {
                response: ResponseInfo {
                    result: vec![],
                    status: reqwest::StatusCode::INTERNAL_SERVER_ERROR.to_string(),
                    time: "".to_string(),
                }
            };
        }
    };

    let val = match res.json().await {
        Ok(json) => {
            let body: Value = json;
            body
        },
        Err(e) => { Value::String(String::from("")) }
    };
    let mut response: Vec<ResponseInfo> = serde_json::from_value(val).unwrap_or(vec![]);
    let body = Ok::<ResponseInfo, reqwest::Error>(response[0].clone()).unwrap_or(ResponseInfo {
        result: vec![],
        status: "".to_string(),
        time: "".to_string(),
    });

    IndexPageState {
        response: body,
    }
}
\end{lstlisting}

\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/client.png}
  \caption{Screenshot des Clients}
  \label{fig:clientscreenshot}
\end{figure}

\subparagraph{REST API} \mbox{} \\

Interaktion der Funktionen: add\_repository fügt zunächst die Eigenschaften, welche dem Aufrufer nicht bekannt sein sollen, aber in der Datenbank gespeichert werden müssen, hinzu. Die aufgerufene Funktion create\_client\_post\_request stellt dann eine HTTP-POST-Anfrage an die Datenbank, um das Repository-Objekt zu speichern. Wenn die Datenbank antwortet, wird die handle\_response-Funktion aufgrufen, um die Antwort zu verarbeiten und als JSON zurückzugeben. create\_client\_post\_request gibt die Antwort an add\_repository und damit den Aufrufer des Endpunktes zurück. 

\begin{lstlisting}[language=Java,frame=single,caption=Programmatischer Endpunkt mit Dokumentation für Swagger (mit CodeGen),label=apione]
#[utoipa::path(
request_body = PostRepository,
responses(
(status = 201, description = "File created successfully.", body = Vec<ResponseInfo>),
(status = 500, description = "Internal Server Error", body = String),
(status = 404, description = "Files not found", body = String)))]
#[post("/repositories")]
pub async fn add_repository(req: web::Json<PostRepository>) -> impl Responder {
    let repo = Repository {
        id: String::from(""),
        name: String::from(&req.name),
        created_at: format!("{}", Local::now()),
        license: String::from(&req.license),
        primary_language: String::from(""),
        commit_count: 0,
        forks_count: 0,
        pull_requests: 0,
        stars_count: 0,
        watchers: 0,
        languages_used: Vec::new(),
    };

    let base_url = env::var("BASE_URL").expect("Base URL not found as environment variable");
    let url = format!("{}/key/repository", base_url);
    info!("URL POST: {}", url);
    let response = create_client_post_request(repo, url).await;
    response
}
\end{lstlisting}


\begin{lstlisting}[language=Java,frame=single,caption=Senden eines HTTP Requests (hier an die Datenbank) mit Headern,label=apitwo]
pub async fn create_client_post_request(req: Repository, url: String) -> impl Responder{
    let user = env::var("DB_USER").expect("No username env. variable found");
    let pw = env::var("DB_PASSWORD").expect("No password env. variable found");
    let client = reqwest::Client::new();
    let res = client.post(url)
        .header("Accept","application/json")
        .header("NS","base")
        .header("DB","base")
        .basic_auth(user, Some(pw))
        .json(&req)
        .send()
        .await
        .expect("Database not reachable.");
    let res = handle_response(res, true).await;
    res
}
\end{lstlisting}

\begin{lstlisting}[language=Java,frame=single,caption=Auflösung des Responses (als Option) mit Pattern Matching,label=apitwo]
async fn handle_response(res: reqwest::Response) -> impl Responder{
    match res.status() {
        reqwest::StatusCode::OK => {
            match res.json().await {
                Ok(json) => {
                    let body: Value = json;
                    HttpResponse::Created().json(body)
                },
                Err(e) => HttpResponse::InternalServerError()
                    .json(format!("Json parsing error: {}", e)),
            }
        },
        reqwest::StatusCode::FORBIDDEN => {
            HttpResponse::Forbidden()
                .json("You are not allowed to access this resource")
        },
        other => {
            HttpResponse::InternalServerError()
                .json(format!("Something went wrong: {}", other))
        },
    }
}
\end{lstlisting}

\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/swagger.png}
  \caption{Implementierte Ressourcen mit Routen und Datenmodellen (Swagger UI Integration)}
  \label{fig:apione}
\end{figure}


\subparagraph{Tests (Hannes)}  \mbox{} \\


\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/data2.png}
  \caption{}
  \label{fig:benchmarkone}
\end{figure}


\begin{figure}[H]
\centering
  \includegraphics[width=\textwidth]{images/data4.png}
  \caption{}
  \label{fig:benchmarktwo}
\end{figure}


\begin{figure}[H]
\centering
  \includegraphics[width=250px]{images/data.png}
  \caption{}
  \label{fig:benchmarkthree}
\end{figure}


\begin{figure}[H]
\centering
  \includegraphics[width=250px]{images/data5.png}
  \caption{}
  \label{fig:benchmarkfour}
\end{figure}


\paragraph{Deployment} \mbox{} \\
Für beide selbst entwickelten Services wird mit Hilfe von Dockerfiles (Listing \ref{deploymentone}) ein Image erstellt und aufs Dockerhub gepusht. In einem produktiven Szenario, insbesondere wenn der Code Closed Source ist, sollte stattdessen eine eigene Docker Registry verwendet werden. Die Schritte zur Öffentlichung sind jedoch bis auf den Host im Command docker push ... dieselben. 

\begin{lstlisting}[language=SQL,frame=single,caption=Dockerfile für die Erstellung des REST-API Images ,label=deploymentone]
FROM rust:1.60.0-bullseye AS build
WORKDIR /app
COPY . .
RUN cargo build --release
RUN mkdir -p /app/lib
RUN cp -LR $(ldd ./target/release/rust-actix-surreal-rest-api | grep "=>" | cut -d ' ' -f 3) /app/lib

FROM scratch AS app
WORKDIR /app
COPY --from=build /app/lib /app/lib
COPY --from=build /lib64/ld-linux-x86-64.so.2 /lib64/ld-linux-x86-64.so.2
COPY --from=build /app/target/release/rust-actix-surreal-rest-api rust-actix-surreal-rest-api
ENV LD_LIBRARY_PATH=/app/lib
ENTRYPOINT ["./rust-actix-surreal-rest-api"]
\end{lstlisting}

Auf dem Server, auf welchem die Services laufen sollen, muss ein Pull der Images erfolgen oder der Pfad zur Registry im docker-compose File angegeben sein, dann wird das Image automatisch bezogen. Die Ausführung von docker-compose up -d erstellt dann aus den Images die Container mit der dargestellten Konfiguration. Die virtuell erstellten Netzwerke in Docker (s. Listing \ref{deploymenttwo} in Zeile 11, 18 und 31) ermöglichen eine zusätzliche Kapselung, der einzig nach außen geöffnete Port ist im Beispiel 8080. In einer produktiven Umgebung wäre hier entweder noch ein weiterer Service in Form eines Reverse Proxys (z.B. nginx oder traefik) vorhanden, welcher über Port 443 erreichbar ist und über LetsEncrypt ein Zertifikat bezieht. Alternativ könnte auf dem Server direkt ein nginx Webserver bereitgestellt werden, Hauptsache die über HTTP erreichbaren Services sind in einem gekapselten Netzwerk nur über die Weiterleitung der Anfragen des Reverse Proxys erreichbar. 

\begin{lstlisting}[language=SQL,frame=single,caption=docker-compose.yml zur Bereitstellung des kompletten Stacks,label=deploymenttwo]
version : '3.8'
services:
  db:
    image: surrealdb/surrealdb:latest
    restart: always
    command: start --user root --pass root memory
    expose:
      - 8000
    volumes:
      - db:/var/lib/surrealdb/data
    networks:
      - backend

  rest-api:
    image: rust-actix-surreal-rest-api    
    expose: 
      - 8088
    networks:
      - backend
      - frontend
    depends_on:
      - db
    environment:
      - BASE_URL=http://db
      - CORS_ALLOW=http://localhost:8080
      
  client:
    image: rust-client    
    ports: 
      - '8080:8080'
    networks:
      - frontend
    depends_on:
      - rest-api
    environment:
      - SERVICE_URL=http://rest-api

networks:
  backend:
\end{lstlisting}

Die dargestellte Form des Deployments ermöglicht eine sehr schnelle Aktualisierung der Services. Der Veröffentlichung des neuen Images würde i.d.R. natürlich ein umfangreiches, automatisiertes Testing vorausgehen, das Image selbst ist dann das Artefakt. Die erneute Ausführung von docker-compose up -d würde dann ausschließlich die Container neu starten, für welche Änderungen der Images festgestellt wurden. Dies dauert maximal einige Sekunden. Um auch dies zu vermeiden wäre es mit wenigen Zeilen zusätzlicher Konfiguration möglich, die Container zu replizieren und nach Terminierung der Verbindung im Reverse Proxy dynamisch die Last zu verteilen. Der Reverse Proxy hat dann dementsprechend gleichzeitig die Funktion eines Loadbalancers. \\
Um den Rahmen nicht zu sprengen, haben wir kein Monitoring und Remote Logging realisiert, auch dies wäre jedoch durch die Nutzung von Docker einfach umzusetzen. Images, z.B. für den oft verwendeten ELK Stack oder alternativ die Kombination von Grafana und Prometheus, sind vorhanden und mit wenigen Anpassungen als weitere Services innerhalb der docker-compose File einsetzbar. Des weiteren würden die Services in einem produktiven Umfeld als Cluster auf physisch getrennten Systemen laufen.\\
Das Deployment kann auf jedem beliebigen Linuxserver erfolgen, auf dem Docker installiert ist. In unserem Fall haben wir Linode (Akamai) als IAAS Anbieter ausgewählt und die Anwendung auf einem Alpine Server mit 1GB RAM bereitgestellt. 


\subsubsection{Anbindung Datenbank} \label{anbindungdatenbank}


\begin{lstlisting}[language=bash,frame=single,caption=CLI Kommandos zur lokalen Installation der Datenbank für Windows\, Linux und macOS,label=dbinstall]
iwr https://windows.surrealdb.com -useb | iex
curl -sSf https://install.surrealdb.com | sh
brew install surrealdb/tap/surreal
\end{lstlisting}

\begin{lstlisting}[language=bash,frame=single,caption=CLI Kommando zur Übertragung der Daten aus der Datei in Listing \ref{sqldbone},label=dbsetup]
cat schemashort.sql | surreal sql --conn http://localhost:8000 --user root --pass root --ns base --db base
\end{lstlisting}


\begin{lstlisting}[language=SQL,frame=single,caption=Ausschnitt der sql Setupdatei,label=sqldbone]
INSERT INTO repository (name, stars_count, forks_count, watchers, pull_requests, primary_language, languages_used, commit_count, created_at, licence) VALUES ('react', 159266, 30464, 8497, 2911, lang:JavaScript, [lang:JavaScript, lang:HTML, lang:CSS], 5562, '2013-05-24T16:15:54Z', 'MIT License');
INSERT INTO repository (name, stars_count, forks_count, watchers, pull_requests, primary_language, languages_used, commit_count, created_at, licence) VALUES ('scikit-learn', 38327, 18225, 4968, 1701, lang:Python, [lang:Python, lang:Cython, lang:HTML, lang:CSS], 4085, '2010-01-10T09:58:52Z', 'BSD-3-Clause License');
INSERT INTO repository (name, stars_count, forks_count, watchers, pull_requests, primary_language, languages_used, commit_count, created_at, licence) VALUES ('angular', 68521, 24536, 6779, 2197, lang:TypeScript, [lang:TypeScript, lang:JavaScript, lang:HTML, lang:CSS], 4248, '2014-09-18T16:12:01Z', 'MIT License');
\end{lstlisting}



\newpage
\section{Übung 4d: Sicherheit von Web APIs}
\subsection{Sicherheitsrisiken in Verbindung mit dem HTTP Protokoll}

\subsubsection{HTTPS und TLS}
HTTP Eigenschaften:
\begin{itemize}
\item ist das Standardprotokoll für die Internetkommunikation
\item arbeitet nach dem Client Server Modell
\item nutzt TCP
\item hat zwei Typen: non-persistent (weniger Overhead, einmalige Verbindung, wird nicht aufrechterhalten) und persistent (Verbindung wird nach Aufbau aufrechterhalten, s. \ref{sockets})
\item funktioniert über Request und Response Message
\item Benutzer- und Serverstatus werden über Cookies aufrechterhalten
\item Webcache kann Geschwindigkeit erhöhen (lokal im Browser oder serverseitig auf Proxy), Response ist 304 (conditional GET)
\item HTTPS (S steht für secure) ist eine Erweiterung von HTTP
\end{itemize}

TLS Eigenschaften: (Wiki)
\begin{itemize}
\item Nachfolger von SSL, steht für Transport Layer Security
\item Verbindung zu HTTPS: kommt im TCP/IP Stack zwischen Transport und Anwendungsebene zum Einsatz und wird i.d.R. zusätzlich zum TCP Protokoll eingesetzt. 
\item ermöglicht eine Ende zu Ende Verschlüsselung von Data in Transit (und ist deshalb z.B. bei Mails durch zusätzliche Teilnehmer zwischen den ``Enden'' nur eingeschränkt sicher)
\item Im TLS Handshake findet ein sicherer Schlüsselaustausch und eine Authentifizierung statt.
\item Für den Schlüsselaustausch sind in den älteren TLS-Versionen verschiedene Algorithmen mit unterschiedlichen Sicherheitsgarantien im Einsatz. Die neueste Version TLS 1.3 verwendet allerdings nur noch das Diffie-Hellman-Schlüsselaustausch Protokoll (DHE oder ECDHE) auf Basis elliptischer Kurven.
\item Dabei wird für jede Verbindung ein neuer Sitzungsschlüssel (Session Key) ausgehandelt. Da dies ohne Verwendung eines Langzeitschlüssels geschieht, erreicht TLS 1.3 Perfect Forward Secrecy.
\item Alle TLS-Handshakes verwenden eine asymmetrische Kryptographie (öffentlicher und privater Schlüssel), aber nicht alle nutzen den privaten Schlüssel beim Generieren von Sitzungsschlüsseln.
\end{itemize}

Vorteile TLS (1.3):
TLS 1.3 hat die Unterstützung für ältere, weniger sichere kryptografische Features eingestellt und unter anderem TLS-Handshakes schneller gemacht. Die Hauptvorteile von TLS 1.3 gegenüber TLS 1.2 sind schnellere Geschwindigkeiten und verbesserte Sicherheit. TLS und verschlüsselte Verbindungen erzeugen naturgemäß einen Overhead bei der Übertragung. HTTP / 2 hat bei diesem Problem durch die Verringerung der Schritte beim Aufbau der TCP Verbindung geholfen, aber TLS 1.3 beschleunigt verschlüsselte Verbindungen durch Funktionen wie TLS false start und Zero Round Trip Time (0-RTT) noch weiter. Die Einführung elliptischer Kurven verbessert zudem bei gleicher Schlüssellänge die Sicherheit und vermeidet beispielsweise Angriffe wie LogJam, die auf dem Number field sieve Algorithmus basieren (welcher die Tatsache ausnutzt, dass immer dieselbe Primzahl verwendet wird). Auch export-grade Funktionalitäten (welche demselben Angriff zugrunde lagen) sind in TLS 1.3 nicht mehr eingebaut.

\subsubsection{Authentifizierungmöglichkeiten HTTP(S)}
Es gibt mehrere Möglichkeiten, Benutzer (Clients) im Rahmen des HTTP-Protokolls zu authentifizieren. Verbreitet sind (Wiki, ssl.com):
\begin{itemize}
\item Basic Authentication: Die Basic Authentication (Basisauthentifizierung) wird seit 2015 durch RFC 7617 spezifiziert und ist eine häufig verwendete Art der HTTP-Authentifizierung. Der Webserver fordert mit Eingabe von Benutzername und Passwort eine Authentifizierung an. Ein Vorteil der Basic Authentication ist ihre Einfachheit in der Implementierung. Ein Nachteil ist, dass die Anmeldeinformationen im Klartext übertragen werden und daher leicht abgefangen werden können. Deshalb sollte diese Methode nur für den Hobbybereich eingesetzt werden.
\item Digest Access Authentication: Die Hashwertauthentifizierung ist ein Verfahren, das die Basic-Authentifizierung ersetzen soll(te). Der Server sendet eine Zeichenfolge zufälliger Daten, auch Nonce genannt, als Challenge an den Client. Der Client reagiert mit einem Hash, der neben anderen Informationen den Benutzernamen, das Kennwort und die Nonce enthält. Die Digest Access Authentication bietet mehr Sicherheit als die Basic Authentication, da sie einen Hash verwendet und somit die Anmeldeinformationen nicht im Klartext übertragen werden.
\end{itemize}

Weitere Verfahren, die im Zusammenhang mit HTTPS eingesetzt werden, sind nicht den direkten Verfahren zuzurechnen, weil sie alle eine dritte Instanz hinzuziehen müssen (Validierung Zertifikate über PKI, Authorisierungs- bzw. Authentifizierungsprüfung über Drittanbieter bei OAuth2 und OIDC).

\subsubsection{Cookies}
\paragraph{Begriff} \mbox{} \\
Cookies sind kleine Textdateien, die von einer Webseite im Internetbrowser eines Nutzers gespeichert werden können. Sie dienen dazu, Informationen über den Nutzer und seine Interaktionen mit der Webseite zu speichern. \\
Cookies können nützlich sein, indem sie beispielsweise Einstellungen im Webbrowser abspeichern oder dafür sorgen, dass ein Warenkorb beim Online-Shopping zu einem späteren Zeitpunkt wieder aufgerufen werden kann. Sie können auch dazu verwendet werden, das Surfverhalten von Nutzern im Internet über einen längeren Zeitraum zu verfolgen und detaillierte Nutzerprofile anzulegen (was eher aus Sicht des Betreibers ein Vorteil ist...). \\
Grundsätzlich werden zwei Arten von Cookies unterschieden: technisch notwendige und technisch nicht notwendige Cookies. Technisch notwendige Cookies sind für das Funktionieren der Webseite notwendig, während technisch nicht notwendige Cookies für Zwecke wie das Verfolgen des Surfverhaltens verwendet werden können. \\
Es ist zwar möglich, eine Webseite ohne Cookies zu betreiben, allerdings kann dies zu Einschränkungen in der Funktionalität führen. Beispielsweise müssten Nutzer bei jedem Besuch der Webseite erneut ihre Einstellungen vornehmen oder sich erneut anmelden. Sofern jedoch eine Persistierung von Nutzerdaten nicht notwendig ist, z.B. bei statischen, rein informativen Seiten, kann auf Cookies verzichtet werden (was oft nicht passiert, weil durch den Einsatz von Tracking, eingebetteten Webfonts usw. auch auf solchen Seiten, Cookies gesetzt werden). Dabei sollte jedoch zwischen tendenziell unkritischen Sessioncookies, die lokal und verschlüsselt gespeichert werden und Trackingcookies, welche übertragen werden, unterschieden werden.   \\  
Ein großer Nachteil von Cookies ist mit ihnen einhergehende Sicherheitsrisiko. Da sie Informationen über den Nutzer und seine Interaktionen mit der Webseite speichern, können sie von Dritten abgefangen und missbraucht werden.

\paragraph{Sicherheitsrisiken (Hannes)} \mbox{} \\
Cookie Poisoning, XSS, Cookiethief


\subsection{Möglichkeiten zur Risikominderung}
\subsubsection{OWASP}

Dem Ranking liegt das OWASP API Security Threat Model zugrunde.\footnote{Vgl. \cite{api-owasp}} Es ist eine Methodologie zur Identifizierung und Bewertung von Bedrohungen für APIs. Es folgt einem strukturierten Ansatz, der aus vier Schritten besteht:
\begin{enumerate}
\item API-Beschreibung: Hier werden die API-Funktionen und Datenobjekte beschrieben.
\item Bedrohungsmodellierung: In diesem Schritt werden potenzielle Bedrohungen identifiziert und priorisiert. Die Bedrohungsmodelle werden auf der Basis der API-Beschreibung entwickelt.
\item Risikobewertung: Die Bedrohungsmodelle werden bewertet, um diejenigen mit dem höchsten Risiko zu identifizieren.
\item Empfehlungen: Basierend auf den identifizierten Bedrohungen und Risiken werden Empfehlungen für Sicherheitsmaßnahmen abgeleitet, um das Risiko zu minimieren.
\end{enumerate}

Die OWASP klassifiziert die Bedrohungen folgendermaßen (mehr Punkte = höhere Gefahr):

\begin{table}[H]
\begin{center}
\begin{tabular}{| L{1.5cm} | L{2.3cm} | L{2.3cm} | L{2.3cm} | L{2.3cm} |}
\hline
Punkte & Exploitability (Ausnutzbarkeit) & Weakness Prevalence (Häufigkeit) & Weakness Detectability (Aufspürbarkeit) & Technical Impact (Auswirkungen) \\ \hline
3 & Easy & Widespread & Easy & Severe \\ \hline
2 & Average & Common & Average & Moderate \\ \hline
1 & Difficult & Difficult & Difficult & Minor \\ \hline
\end{tabular}
\caption{OWASP Thread Model, allgemeine Form}
\label{threadmodelallg}
\end{center}
\end{table}

Die Methodologie soll helfen, API-Designs zu verbessern und Entwicklern zu helfen, sicherere APIs zu erstellen. Für die ausgewählten Lücken geben wir zunächst die (aufgrund der technischen Fachtermini im englischen belassene) Beschreibung der OWASP Foundation an. Anschließend zeigen wir je anhand eines negativen und positiven Beispiels, wie das Ausnutzen der Lücke eingeschränkt werden kann. Dabei wird im jeweiligen Beispiel nur die entsprechende Schwachstelle beachtet, d.h. andere Teile im Beispiel können hinsichtlich weiterer Schwachstellen durchaus anfällig sein. Zudem vereinfachen die Beispiele die oftmals komplexen Problematiken natürlich.


\paragraph{Ausgewählte Schwachstellen (5)} \mbox{} \\
\begin{table}[H]
\begin{center}
\begin{tabular}{| L{2.3cm} | L{2.3cm} | L{2.3cm} | L{2.3cm} | L{2.3cm} |}
\hline
Vulnerability & Exploitability (Ausnutzbarkeit) & Weakness Prevalence (Häufigkeit) & Weakness Detectability (Aufspürbarkeit) & Technical Impact (Auswirkungen) \\ \hline
Broken Object Level Authorization & 3 & 3 & 2 & 3 \\ \hline
Excessive Data Exposure & 3 & 2 & 2 & 2 \\ \hline
Broken Function Level Authorization & 3 & 2 & 1 & 2 \\ \hline
Injection & 3 & 2 & 3 & 3 \\ \hline
Insufficient Logging \& Monitoring & 2 & 3 & 1 & 2 \\ \hline
\end{tabular}
\caption{OWASP Thread Model für APIs für die 5 ausgewählten Sicherheitslücken}
\label{threadmodel}
\end{center}
\end{table}

\subparagraph{Broken Object Level Authorization} \mbox{} \\

\begin{formal}
APIs tend to expose endpoints that handle object identifiers, creating a wide attack surface Level Access Control issue. Object level authorization checks should be considered in every function that accesses a data source using an input from the user.
\end{formal}

Das erste Beispiel (Listing \ref{owasponebad}) stellt ein Sicherheitsrisiko dar, weil keine Überprüfung der Zugriffsberechtigungen für den Abruf einer bestimmten Ressource aus der Datenbank vorgenommen wird. Jeder Benutzer, der auf diese Route zugreift, kann alle Elemente abrufen, unabhängig von den Zugriffsberechtigungen.

\begin{lstlisting}[language={[Sharp]C},frame=single,caption=Negativbeispiel Broken Object Level Authorization,label=owasponebad]
[HttpGet("items/{id}")] 
public Task<IActionResult<Item>> GetItem(int id) 
{ 
	var item = await _context.Items
        .Where(i => i.Id == id)
        .SingleOrDefaultAsync();
    return Ok(item ?? NotFound());
}
\end{lstlisting}

Das zweite Beispiel (Listing \ref{owasponegood}) verbessert die Sicherheit, da überprüft wird, ob der angemeldete Benutzer (current user) das Eigentümer-Attribut des Elements besitzt, bevor das Element zurückgegeben wird. Auf diese Weise wird sichergestellt, dass nur der Eigentümer des Elements darauf zugreifen kann und andere Benutzer keinen Zugriff darauf haben.

\begin{lstlisting}[language={[Sharp]C},frame=single,caption=Positivbeispiel Broken Object Level Authorization,label=owasponegood]

[HttpGet("items/{id}")]
public async Task<IActionResult<Item>> GetItem(int id)
{
    var currentUser = HttpContext.User;
    var item = await _context.Items
        .Where(i => i.Id == id && i.OwnerId == currentUser.FindFirstValue(ClaimTypes.NameIdentifier))
        .SingleOrDefaultAsync();

    return Ok(item ?? NotFound());
}
\end{lstlisting}


\subparagraph{Excessive Data Exposure} \mbox{} \\
\begin{formal}
Looking forward to generic implementations, developers tend to expose all object properties without considering their individual sensitivity, relying on clients to perform the data filtering before displaying it to the user.
\end{formal}
In diesem Beispiel (Listing \ref{owasptwobad}) enthält der Response zum Abrufen eines Order-Objekts das Kundenobjekt als Property. Es mag Gründe für ein solches Datenmodell geben, in dem Fall werden aber ohne Einschränkung durch die direkte Rückgabe alle Informationen preisgegeben. Eine Erweiterung des Objektes  um weitere Eigenschaften durch einen Entwickler würde über diese Route die neue Eigenschaft ungeprüft mit zurückgeben. Wenn ein Angreifer auf diesen Endpunkt zugreifen würde, könnte er diese sensiblen Informationen abrufen, obwohl sie für die Erfüllung der Anfrage nicht erforderlich sind.

\begin{lstlisting}[language={[Sharp]C},frame=single,caption=Negativbeispiel Excessive Data Exposure,label=owasptwobad]
[HttpGet("order/{id}")]
public IActionResult<Order> GetOrder(int id)
{
    var order = _context.Orders.Include(o => o.Customer).FirstOrDefault(o => o.Id == id);
    return Ok(order);
}

public record Order(int Id, int Total, DateTime Date, int CustomerId)
\end{lstlisting}

In diesem Beispiel (Listing \ref{owasptwogood}) gibt der API-Endpunkt nur die für die Erfüllung der Anforderung erforderlichen Informationen zurück (d. h. die Auftragskennung, den Gesamtbetrag und das Datum). Das Response Model entspricht nicht dem Rückgabeobjekt von \_context.Orders und die notwendigen Properties werden auf den response gemappt. Das o.g. Problem, z.B. bei einer Erweiterung, tritt nicht auf und neue Property müsste explizit auch dem Response Model hinzugefügt werden und zusätzlich gemappt werden.

\begin{lstlisting}[language={[Sharp]C},frame=single,caption=Positivbeispiel Excessive Data Exposure,label=owasptwogood]

[HttpGet("orders/{id}")]
public IActionResult<OrderResponse> GetOrder(int id)
{
    var order = _context.Orders.FirstOrDefault(o => o.Id == id);

    if (order == null)
    {
        return NotFound();
    }

    OrderResponse response = new {
        Id = order.Id,
        Total = order.Total,
        Date = order.Date
    };

    return Ok(response);
}
public record Order(int Id, int Total, DateTime Date, int CustomerId)
public record OrderResponse(int Id, int Total, DateTime Date)
\end{lstlisting}


\subparagraph{Broken Function Level Authorization} \mbox{} \\
\begin{formal}
Complex access control policies with different hierarchies, groups, and roles, and an unclear separation between administrative and regular functions, tend to lead to authorization flaws. By exploiting these issues, attackers gain access to other users’ resources and/or administrative functions.
\end{formal}

Die folgenden beiden Beispiele (Listings \ref{owaspthreebad} und \ref{owaspthreegood})unterschieden sich lediglich in der Annotation in der zweiten Methode, welche vorgibt, welche Rollen berechtigt sind, den Endpunkt überhaupt aufzurufen. Die Überprüfung innerhalb der Methode wäre bei Implementierung der Standardlibrary von .NET gar nicht nötig und ist hier nur zur Verdeutlichung eingefügt. Die erste Methode könnte hingegen über die entsprechende Route von jedem Nutzer aufgerufen werden und die entsprechenden Informationen über den zurückgegebenen User unabhängig der Autorisierung des Aufrufers eingesehen und verwendet werden.

\begin{lstlisting}[language={[Sharp]C},frame=single,caption=Negativbeispiel Broken Function Level Authorization,label=owaspthreebad]
[HttpGet("orders/{id}")]
public IActionResult<Order> GetOrder(int id)
{
    Order order = _context.Orders.Find(id);
    return Ok(order ?? NotFound());    
}
\end{lstlisting}


\begin{lstlisting}[language={[Sharp]C},frame=single,caption=Positivbeispiel Broken Function Level Authorization,label=owaspthreegood]
[HttpGet("orders/{id}")]
[Authorize(Roles = "admin, manager")]
public IActionResult<Order> GetOrder(int id)
{
    var currentUser = HttpContext.User;
    if (!currentUser.IsInRole("admin") || !currentUser.IsInRole("manager"))
    {
        return Forbid();
    }
    Order order = _context.Orders.Find(id);
    return Ok(order ?? NotFound());
}
\end{lstlisting}


\subparagraph{Injection (hier SQL)} \mbox{} \\
\begin{formal}
Injection flaws, such as SQL, NoSQL, Command Injection, etc., occur when untrusted data is sent to an interpreter as part of a command or query. The attacker's malicious data can trick the interpreter into executing unintended commands or accessing data without proper authorization.
\end{formal}

Das negative Beispiel (Listing \ref{owaspfourbad}) weist eine SQL-Injection-Vulnerability auf, da der Wert der Variable "id" direkt in die SQL-Abfrage eingefügt (injected) wird. Ein Angreifer kann die Eingabe manipulieren, um die Abfrage zu verändern und unautorisierten Zugriff auf die Datenbank zu erlangen oder schädlichen Code einzufügen.

\begin{lstlisting}[language={[Sharp]C},frame=single,caption=Negativbeispiel Injection,label=owaspfourbad]
[HttpGet("users/{id}")]
public IActionResult<User> GetUser(string id)
{
    string query = $"SELECT * FROM Users WHERE Id = '{id}'";
    // ...
}
\end{lstlisting}

Im Gegensatz dazu verwendet das positive Beispiel in Listing \ref{owasfourgood} parameterisierte Abfragen und schützt damit gegen SQL-Injection-Attacken, da der Wert von "id" als Parameter an die Abfrage übergeben wird, anstatt direkt in die Abfrage eingefügt zu werden. Als zusätzliche Sicherheitsmaßnahme wird statt einer id eine GUID verwendet, welche im richtigen Format vorliegen muss und es bei der Abfrage erschwert, id's zu ``erraten'' (was Security by Obscurity wäre - also für sich keinerlei Sicherheit bietet, in Kombination jedoch sinnvoll ist).

\begin{lstlisting}[language={[Sharp]C},frame=single,caption=Positivbeispiel Injection,label=owaspfourgood]
[HttpGet("users/{id}")]
public IActionResult<User> GetUser(Guid id)
{
    string query = "SELECT * FROM Users WHERE Id = @id";
    var command = new SqlCommand(query, connection);
    command.Parameters.AddWithValue("@id", id);
    // ...
}
\end{lstlisting}


\subparagraph{Insufficient Logging \& Monitoring} \mbox{} \\
\begin{formal}
Insufficient logging and monitoring, coupled with missing or ineffective integration with incident response, allows attackers to further attack systems, maintain persistence, pivot to more systems to tamper with, extract, or destroy data. Most breach studies demonstrate the time to detect a breach is over 200 days, typically detected by external parties rather than internal processes or monitoring.
\end{formal}

Wir greifen die Problematik der SQL-Injection auf - in diesem Beispiel (Listing \ref{owaspfivebad}) wird durch Parameterisierung versucht, einen SQL-Injection-Angriff zu verhindern. Allerdings wird im Falle eines Fehlers beim Ausführen des SQL-Statements nur eine allgemeine Fehlermeldung an den Client zurückgegeben. Es gibt keine weiteren Maßnahmen zur Überwachung oder Protokollierung des Vorfalls.

\begin{lstlisting}[language={[Sharp]C},frame=single,caption=Negativbeispiel Improper Assets Management,label=owaspfivebad]
[HttpGet("users/{id}")]
public IActionResult GetUser(string id)
{
    try
    {
        string query = "SELECT * FROM Users WHERE Id = @id";
    	   var command = new SqlCommand(query, connection);
        command.Parameters.AddWithValue("@id", id);
        // ...
    }
    catch (Exception ex)
    {
        _logger.LogError(ex, "Error occurred while getting user with ID {id}", id);
        return StatusCode(500);
    }
}
\end{lstlisting}

In positiven Beispiel (Listing \ref{owaspfivegood}) wird ebenfalls versucht, einen SQL-Injection-Angriff zu verhindern, indem ein parametrisiertes SQL-Statement verwendet wird. Wenn jedoch ein Fehler beim Ausführen des Statements auftritt, wird der Fehler sowohl protokolliert als auch an einen Remote-Logger gesendet, der in das mit einem Monitoring Tool verbundenen Sink schreibt. Je nach Incidence oder bei wiederholten Vorfällen kann dann entsprechend (automatisch) reagiert werden, um möglicherweise eine weitere Attacke zu verhindern (z.B. durch ein Blacklisting der IP).

\begin{lstlisting}[language={[Sharp]C},frame=single,caption=Positivbeispiel Improper Assets Management,label=owaspfivegood]
[HttpGet("users/{id}")]
public IActionResult<User> GetUser(string id)
{
    try
    {
        string query = "SELECT * FROM Users WHERE Id = @id";
        var command = new SqlCommand(query, connection);
        command.Parameters.AddWithValue("@id", id);
        // ...
    }
    catch (SqlException ex)
    {
        _logger.LogError(ex, "Error occurred while getting user with ID {id}", id);
        _monitoringService.LogEvent(new EventLog { 
            EventType = "Security",
            EventLevel = "Warning",
            EventMessage = "Failed attempt to get user with ID " + id
        });
        return StatusCode(500);
    }
    catch (Exception ex)
    {
        _logger.LogError(ex, "Unknown error occurred while getting user with ID {id}", id);
        _monitoringService.LogEvent(new EventLog { 
            EventType = "Common",
            EventLevel = "Error",
            EventMessage = "Unknown error occurred while getting user with ID " + id
        });
        return StatusCode(500);
    }
}
\end{lstlisting}

\paragraph{Zwei ausgewählte Testmöglichkeiten (Hannes)} \mbox{} \\
 OWASP ZAP, Burp Suite, Postman Interceptor, Wireshark
 injection: sqlmap, XSStrike, SQLNinja
 ELK Stack
 
\subsubsection{OAuth 2 und OIDC (Danny)}
Analysieren Sie die grundlegende Arbeitsweise von OAuth2
\begin{itemize}
\item Welche grundlegenden Rollen werden in OAuth2 unterscheiden?
\item Welche Zusammenhänge bestehen zwischen OAuth2 und OIDC?
\end{itemize}

\subsection{Praktische Anwendung von OAuth2 (Hannes)}
\subsubsection{Testwerkzeuge}
Verwenden Sie ein Testwerkzeug zur Nutzung von Web APIs und beschreiben Sie exakt die Schritte und Konfigurationen von mindestens 3 OAuth2 konformen Funktionsaufrufen (request), sie deren erhaltenen Antworten (response)

\subsubsection{Implementierung}
\begin{lstlisting}[language={[Sharp]C},frame=single,caption=OAuth2 und OICD in Rust,label=owaspfivegood]
use std::env;
use std::io::{BufRead, BufReader, Write};
use std::net::TcpListener;
use std::process::exit;
use dotenv::dotenv;
use serde::{Deserialize, Serialize};
use url::Url;

use openidconnect::core::{
    CoreAuthDisplay, CoreClaimName, CoreClaimType, CoreClient, CoreClientAuthMethod, CoreGrantType,
    CoreIdTokenClaims, CoreIdTokenVerifier, CoreJsonWebKey, CoreJsonWebKeyType, CoreJsonWebKeyUse,
    CoreJweContentEncryptionAlgorithm, CoreJweKeyManagementAlgorithm, CoreJwsSigningAlgorithm,
    CoreResponseMode, CoreResponseType, CoreRevocableToken, CoreSubjectIdentifierType,
};
use openidconnect::reqwest::http_client;
use openidconnect::{
    AdditionalProviderMetadata, AuthenticationFlow, AuthorizationCode, ClientId, ClientSecret,
    CsrfToken, IssuerUrl, Nonce, OAuth2TokenResponse, ProviderMetadata, RedirectUrl, RevocationUrl,
    Scope,
};

fn handle_error<T: std::error::Error>(fail: &T, msg: &'static str) {
    let mut err_msg = format!("ERROR: {}", msg);
    let mut cur_fail: Option<&dyn std::error::Error> = Some(fail);
    while let Some(cause) = cur_fail {
        err_msg += &format!("\n    caused by: {}", cause);
        cur_fail = cause.source();
    }
    println!("{}", err_msg);
    exit(1);
}

#[derive(Clone, Debug, Deserialize, Serialize)]
struct RevocationEndpointProviderMetadata {
    revocation_endpoint: String,
}
impl AdditionalProviderMetadata for RevocationEndpointProviderMetadata {}
type GoogleProviderMetadata = ProviderMetadata<
    RevocationEndpointProviderMetadata,
    CoreAuthDisplay,
    CoreClientAuthMethod,
    CoreClaimName,
    CoreClaimType,
    CoreGrantType,
    CoreJweContentEncryptionAlgorithm,
    CoreJweKeyManagementAlgorithm,
    CoreJwsSigningAlgorithm,
    CoreJsonWebKeyType,
    CoreJsonWebKeyUse,
    CoreJsonWebKey,
    CoreResponseMode,
    CoreResponseType,
    CoreSubjectIdentifierType,
>;

fn main() {
    env_logger::init();
    dotenv().ok();
    env::set_var("GOOGLE_CLIENT_ID", "46529231076-nnm9omgbt0bkof4pru8psjqc4vrvbh1b.apps.googleusercontent.com");
    env::set_var("GOOGLE_CLIENT_SECRET", "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");


    let google_client_id = ClientId::new(
        env::var("GOOGLE_CLIENT_ID").expect("Missing the GOOGLE_CLIENT_ID environment variable."),
    );
    let google_client_secret = ClientSecret::new(
        env::var("GOOGLE_CLIENT_SECRET")
            .expect("Missing the GOOGLE_CLIENT_SECRET environment variable."),
    );
    let issuer_url =
        IssuerUrl::new("https://accounts.google.com".to_string()).expect("Invalid issuer URL");

    let provider_metadata = GoogleProviderMetadata::discover(&issuer_url, http_client)
        .unwrap_or_else(|err| {
            handle_error(&err, "Failed to discover OpenID Provider");
            unreachable!();
        });

    let revocation_endpoint = provider_metadata
        .additional_metadata()
        .revocation_endpoint
        .clone();
    println!(
        "Discovered Google revocation endpoint: {}",
        revocation_endpoint
    );

    let client = CoreClient::from_provider_metadata(
        provider_metadata,
        google_client_id,
        Some(google_client_secret),
    )
        .set_redirect_uri(
            RedirectUrl::new("http://localhost:8080".to_string()).expect("Invalid redirect URL"),
        )
        .set_revocation_uri(
            RevocationUrl::new(revocation_endpoint).expect("Invalid revocation endpoint URL"),
        );

    let (authorize_url, csrf_state, nonce) = client
        .authorize_url(
            AuthenticationFlow::<CoreResponseType>::AuthorizationCode,
            CsrfToken::new_random,
            Nonce::new_random,
        )
        .add_scope(Scope::new("email".to_string()))
        .add_scope(Scope::new("profile".to_string()))
        .url();

    println!("Open this URL in your browser:\n{}\n", authorize_url);

    let listener = TcpListener::bind("127.0.0.1:8080").unwrap();
    let (mut stream, _) = listener.accept().unwrap();

    let code;
    let state;
    {
        let mut reader = BufReader::new(&stream);

        let mut request_line = String::new();
        reader.read_line(&mut request_line).unwrap();

        let redirect_url = request_line.split_whitespace().nth(1).unwrap();
        let url = Url::parse(&("http://localhost".to_string() + redirect_url)).unwrap();

        let code_pair = url
            .query_pairs()
            .find(|pair| {
                let &(ref key, _) = pair;
                key == "code"
            })
            .unwrap();

        let (_, value) = code_pair;
        code = AuthorizationCode::new(value.into_owned());

        let state_pair = url
            .query_pairs()
            .find(|pair| {
                let &(ref key, _) = pair;
                key == "state"
            })
            .unwrap();

        let (_, value) = state_pair;
        state = CsrfToken::new(value.into_owned());
    }

    let message = "Go back to your terminal :)";
    let response = format!(
        "HTTP/1.1 200 OK\r\ncontent-length: {}\r\n\r\n{}",
        message.len(),
        message
    );
    stream.write_all(response.as_bytes()).unwrap();

    println!("Google returned the following code:\n{}\n", code.secret());
    println!(
        "Google returned the following state:\n{} (expected `{}`)\n",
        state.secret(),
        csrf_state.secret()
    );

    let token_response = client
        .exchange_code(code)
        .request(http_client)
        .unwrap_or_else(|err| {
            handle_error(&err, "Failed to contact token endpoint");
            unreachable!();
        });

    println!(
        "Google returned access token:\n{}\n",
        token_response.access_token().secret()
    );
    println!("Google returned scopes: {:?}", token_response.scopes());

    let id_token_verifier: CoreIdTokenVerifier = client.id_token_verifier();
    let id_token_claims: &CoreIdTokenClaims = token_response
        .extra_fields()
        .id_token()
        .expect("Server did not return an ID token")
        .claims(&id_token_verifier, &nonce)
        .unwrap_or_else(|err| {
            handle_error(&err, "Failed to verify ID token");
            unreachable!();
        });
    println!("Google returned ID token: {:?}", id_token_claims);


    let token_to_revoke: CoreRevocableToken = match token_response.refresh_token() {
        Some(token) => token.into(),
        None => token_response.access_token().into(),
    };

    client
        .revoke_token(token_to_revoke)
        .expect("no revocation_uri configured")
        .request(http_client)
        .unwrap_or_else(|err| {
            handle_error(&err, "Failed to contact token revocation endpoint");
            unreachable!();
        });
}
\end{lstlisting}

\newpage

\bibliographystyle{te}

\bibliography{citation}

\end{document}